{"url": "https://techcrunch.com/2024/12/14/what-are-ai-world-models-and-why-do-they-matter/", "title": "What are AI \u2018world models,\u2019 and why do they matter?", "authors": ["Kyle Wiggers", "Ai Editor", "Amanda Silberling", "Rebecca Bellan", "Lorenzo Franceschi-Bicchierai", "Sean O'Kane", "Kirsten Korosec", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media", "Min-Width"], "publication_date": "2024-12-14T00:00:00", "text": "World models, also known as world simulators, are being touted by some as the next big thing in AI.\n\nAI pioneer Fei-Fei Li\u2019s World Labs has raised $230 million to build \u201clarge world models,\u201d and DeepMind hired one of the creators of OpenAI\u2019s video generator, Sora, to work on \u201cworld simulators.\u201d (Sora was released on Monday; here are some early impressions.)\n\nBut what the heck are these things?\n\nWorld models take inspiration from the mental models of the world that humans develop naturally. Our brains take the abstract representations from our senses and form them into more concrete understanding of the world around us, producing what we called \u201cmodels\u201d long before AI adopted the phrase. The predictions our brains make based on these models influence how we perceive the world.\n\nA paper by AI researchers David Ha and J\u00fcrgen Schmidhuber gives the example of a baseball batter. Batters have milliseconds to decide how to swing their bat \u2014 shorter than the time it takes for visual signals to reach the brain. The reason they\u2019re able to hit a 100-mile-per-hour fastball is because they can instinctively predict where the ball will go, Ha and Schmidhuber say.\n\n\u201cFor professional players, this all happens subconsciously,\u201d the research duo writes. \u201cTheir muscles reflexively swing the bat at the right time and location in line with their internal models\u2019 predictions. They can quickly act on their predictions of the future without the need to consciously roll out possible future scenarios to form a plan.\u201d\n\nIt\u2019s these subconscious reasoning aspects of world models that some believe are prerequisites for human-level intelligence.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nModeling the world\n\nWhile the concept has been around for decades, world models have gained popularity recently in part because of their promising applications in the field of generative video.\n\nMost, if not all, AI-generated videos veer into uncanny valley territory. Watch them long enough and something bizarre will happen, like limbs twisting and merging into each other.\n\nWhile a generative model trained on years of video might accurately predict that a basketball bounces, it doesn\u2019t actually have any idea why \u2014 just like language models don\u2019t really understand the concepts behind words and phrases. But a world model with even a basic grasp of why the basketball bounces like it does will be better at showing it do that thing.\n\nTo enable this kind of insight, world models are trained on a range of data, including photos, audio, videos, and text, with the intent of creating internal representations of how the world works, and the ability to reason about the consequences of actions.\n\nA sample from AI startup Runway\u2019s Gen-3 video generation model. Image Credits:Runway\n\n\u201cA viewer expects that the world they\u2019re watching behaves in a similar way to their reality,\u201d Alex Mashrabov, Snap\u2019s ex-AI chief of AI and the CEO of Higgsfield, which is building generative models for video, said. \u201cIf a feather drops with the weight of an anvil or a bowling ball shoots up hundreds of feet into the air, it\u2019s jarring and takes the viewer out of the moment. With a strong world model, instead of a creator defining how each object is expected to move \u2014 which is tedious, cumbersome, and a poor use of time \u2014 the model will understand this.\u201d\n\nBut better video generation is only the tip of the iceberg for world models. Researchers including Meta chief AI scientist Yann LeCun say the models could someday be used for sophisticated forecasting and planning in both the digital and physical realm.\n\nIn a talk earlier this year, LeCun described how a world model could help achieve a desired goal through reasoning. A model with a base representation of a \u201cworld\u201d (e.g. a video of a dirty room), given an objective (a clean room), could come up with a sequence of actions to achieve that objective (deploy vacuums to sweep, clean the dishes, empty the trash) not because that\u2019s a pattern it has observed but because it knows at a deeper level how to go from dirty to clean.\n\n\u201cWe need machines that understand the world; [machines] that can remember things, that have intuition, have common sense \u2014 things that can reason and plan to the same level as humans,\u201d LeCun said. \u201cDespite what you might have heard from some of the most enthusiastic people, current AI systems are not capable of any of this.\u201d\n\nWhile LeCun estimates that we\u2019re at least a decade away from the world models he envisions, today\u2019s world models are showing promise as elementary physics simulators.\n\nSora controlling a player in Minecraft \u2014 and rendering the world. Image Credits:OpenAI\n\nOpenAI notes in a blog that Sora, which it considers to be a world model, can simulate actions like a painter leaving brush strokes on a canvas. Models like Sora \u2014 and Sora itself \u2014 can also effectively simulate video games. For example, Sora can render a Minecraft-like UI and game world.\n\nFuture world models may be able to generate 3D worlds on demand for gaming, virtual photography, and more, World Labs co-founder Justin Johnson said on an episode of the a16z podcast.\n\n\u201cWe already have the ability to create virtual, interactive worlds, but it costs hundreds and hundreds of millions of dollars and a ton of development time,\u201d Johnson said. \u201c[World models] will let you not just get an image or a clip out, but a fully simulated, vibrant, and interactive 3D world.\u201d\n\nHigh hurdles\n\nWhile the concept is enticing, many technical challenges stand in the way.\n\nTraining and running world models requires massive compute power even compared to the amount currently used by generative models. While some of the latest language models can run on a modern smartphone, Sora (arguably an early world model) would require thousands of GPUs to train and run, especially if their use becomes commonplace.\n\nWorld models, like all AI models, also hallucinate \u2014 and internalize biases in their training data. A world model trained largely on videos of sunny weather in European cities might struggle to comprehend or depict Korean cities in snowy conditions, for example, or simply do so incorrectly.\n\nA general lack of training data threatens to exacerbate these issues, says Mashrabov.\n\n\u201cWe have seen models being really limited with generations of people of a certain type or race,\u201d he said. \u201cTraining data for a world model must be broad enough to cover a diverse set of scenarios, but also highly specific to where the AI can deeply understand the nuances of those scenarios.\u201d\n\nIn a recent post, AI startup Runway\u2019s CEO, Crist\u00f3bal Valenzuela, says that data and engineering issues prevent today\u2019s models from accurately capturing the behavior of a world\u2019s inhabitants (e.g. humans and animals). \u201cModels will need to generate consistent maps of the environment,\u201d he said, \u201cand the ability to navigate and interact in those environments.\u201d\n\nA Sora-generated video. Image Credits:OpenAI\n\nIf all the major hurdles are overcome, though, Mashrabov believes that world models could \u201cmore robustly\u201d bridge AI with the real world \u2014 leading to breakthroughs not only in virtual world generation but robotics and AI decision-making.\n\nThey could also spawn more capable robots.\n\nRobots today are limited in what they can do because they don\u2019t have an awareness of the world around them (or their own bodies). World models could give them that awareness, Mashrabov said \u2014 at least to a point.\n\n\u201cWith an advanced world model, an AI could develop a personal understanding of whatever scenario it\u2019s placed in,\u201d he said, \u201cand start to reason out possible solutions.\u201d\n\nTechCrunch has an AI-focused newsletter! Sign up here to get it in your inbox every Wednesday.\n\nThis story originally published October 28, 2024, and was updated December 14, 2024, with new updates about Sora."}