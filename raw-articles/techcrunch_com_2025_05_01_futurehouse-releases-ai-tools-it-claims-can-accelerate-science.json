{"url": "https://techcrunch.com/2025/05/01/futurehouse-releases-ai-tools-it-claims-can-accelerate-science/", "title": "FutureHouse releases AI tools it claims can accelerate science", "authors": ["Kyle Wiggers", "Ai Editor", "Lorenzo Franceschi-Bicchierai", "Sean O'Kane", "Kirsten Korosec", "Tim De Chant", "Cindy Zackney", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media", "Min-Width"], "publication_date": "2025-05-01T00:00:00", "text": "FutureHouse, an Eric Schmidt-backed nonprofit that aims to build an \u201cAI scientist\u201d within the next decade, has launched its first major product: a platform and API with AI-powered tools designed to support scientific work.\n\nMany, many startups are racing to develop AI research tools for the scientific domain, and some have with massive amounts of VC funding behind them. Tech giants seem bullish on AI for science, too \u2014 earlier this year, Google unveiled \u201cAI co-scientist,\u201d which the company said could aid scientists in creating hypotheses and experimental research plans.\n\nThe CEOs of AI companies OpenAI and Anthropic have asserted that AI tools could massively accelerate scientific discovery, particularly in medicine. But many researchers don\u2019t consider AI today to be especially useful in guiding the scientific process, largely due to its unreliability.\n\nFutureHouse on Thursday released four AI tools: Crow, Falcon, Owl and Phoenix. Crow can search scientific literature and answer questions about it; Falcon can conduct deeper literature searches, including of scientific databases; Owl looks for previous work in a given subject area; and Phoenix uses tools to help plan chemistry experiments.\n\nToday, we are launching the first publicly available AI Scientist, via the FutureHouse Platform.\n\n\n\nOur AI Scientist agents can perform a wide variety of scientific tasks better than humans. By chaining them together, we've already started to discover new biology really fast. With\u2026 pic.twitter.com/wMMmZoGZPI \u2014 Sam Rodriques (@SGRodriques) May 1, 2025\n\n\u201cUnlike other [AIs], FutureHouse\u2019s have access to a vast corpus of high-quality open-access papers and specialized scientific tools,\u201d the nonprofit wrote in a blog post. \u201cThey [also] have transparent reasoning and use a multi-stage process to consider each source in more depth [\u2026] By chaining these [AI]s together, at scale, scientists can greatly accelerate the pace of scientific discovery.\u201d\n\nTellingly, FutureHouse is yet to achieve a scientific breakthrough or make a novel discovery with its AI tools.\n\nPart of the challenge in developing an \u201cAI scientist\u201d is anticipating an untold number of confounding factors. AI might come in handy in areas where broad exploration is needed, like narrowing down a vast list of possibilities, but it\u2019s less clear whether it can do the kind of out-of-the-box problem-solving that leads to bonafide breakthroughs.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nResults from AI systems designed for science have so far been mostly underwhelming. In 2023, Google said around 40 new materials had been synthesized with the help of one of its AIs, called GNoME. But an outside analysis found not even one of those materials was, in fact, net new.\n\nAI\u2019s technical shortcomings and risks, such as its tendency to hallucinate, also make scientists wary of endorsing it for serious work. Even well-designed studies could end up being tainted by misbehaving AI, which struggles with executing high-precision work.\n\nIndeed, FutureHouse acknowledges that its AI tools \u2014 Phoenix in particular \u2014 may make mistakes.\n\n\u201cWe are releasing [this] now in the spirit of rapid iteration,\u201d the company said in its blog post. \u201cPlease provide feedback as you use it.\u201d"}