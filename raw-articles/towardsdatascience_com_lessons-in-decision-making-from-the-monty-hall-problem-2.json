{"url": "https://towardsdatascience.com/lessons-in-decision-making-from-the-monty-hall-problem-2/", "title": "\ud83d\udeaa\ud83d\udeaa\ud83d\udc10 Lessons in Decision Making from the Monty Hall Problem", "authors": ["Eyal Kazin", "Luis Fernando P\u00e9rez Armas", "Luigi Battistoni", "Qitian Wu", "Christabelle Pabalan", "\u00c1lvaro M\u00e9ndez Civieta", "Tds Editors", "Murray Gillin", ".Wp-Block-Post-Author-Name Box-Sizing Border-Box"], "publication_date": "2025-05-15T19:55:47+00:00", "text": "Problem is a well-known brain teaser from which we can learn important lessons in Decision Making that are useful in general and in particular for data scientists.\n\nIf you are not familiar with this problem, prepare to be perplexed \ud83e\udd2f. If you are, I hope to shine light on aspects that you might not have considered \ud83d\udca1.\n\nI introduce the problem and solve with three types of intuitions:\n\nCommon \u2014 The heart of this post focuses on applying our common sense to solve this problem. We\u2019ll explore why it fails us \ud83d\ude15 and what we can do to intuitively overcome this to make the solution crystal clear \ud83e\udd13. We\u2019ll do this by using visuals \ud83c\udfa8 , qualitative arguments and some basic probabilities (not too deep, I promise).\n\n\u2014 The heart of this post focuses on applying our common sense to solve this problem. We\u2019ll explore why it fails us \ud83d\ude15 and what we can do to intuitively overcome this to make the solution crystal clear \ud83e\udd13. We\u2019ll do this by using visuals \ud83c\udfa8 , qualitative arguments and some basic probabilities (not too deep, I promise). Bayesian \u2014 We will briefly discuss the importance of belief propagation.\n\n\u2014 We will briefly discuss the importance of belief propagation. Causal \u2014 We will use a Graph Model to visualise conditions required to use the Monty Hall problem in real world settings.\n\n\ud83d\udea8Spoiler alert \ud83d\udea8 I haven\u2019t been convinced that there are any, but the thought process is very useful.\n\nI summarise by discussing lessons learnt for better data decision making.\n\nIn regards to the Bayesian and Causal intuitions, these will be presented in a gentle form. For the mathematically inclined \u2694\ufe0f I also provide supplementary sections with short Deep Dives into each approach after the summary. (Note: These are not required to appreciate the main points of the article.)\n\nBy examining different aspects of this puzzle in probability \ud83e\udde9 you will hopefully be able to improve your data decision making \u2696\ufe0f.\n\nFirst, some history. Let\u2019s Make a Deal is a USA television game show that originated in 1963. As its premise, audience participants were considered traders making deals with the host, Monty Hall \ud83c\udfa9.\n\nAt the heart of the matter is an apparently simple scenario:\n\nA trader is posed with the question of choosing one of three doors for the opportunity to win a luxurious prize, e.g, a car \ud83d\ude97. Behind the other two were goats \ud83d\udc10.\n\nThe trader is shown three closed doors.\n\nThe trader chooses one of the doors. Let\u2019s call this (without loss of generalisability) door A and mark it with a \u261d\ufe0f.\n\nKeeping the chosen door \u261d\ufe0f closed\ufe0f, the host reveals one of the remaining doors showing a goat \ud83d\udc10 (let\u2019s call this door C).\n\nThe trader chooses door \u261d\ufe0f and the the host \ud83c\udfa9 reveals door C showing a goat.\n\nThe host then asks the trader if they would like to stick with their first choice \u261d\ufe0f or switch to the other remaining one (which we\u2019ll call door B).\n\nIf the trader guesses correct they win the prize \ud83d\ude97. If not they\u2019ll be shown another goat \ud83d\udc10 (also referred to as a zonk).\n\nWhat is the probability of being Zonked? Credit: Wikipedia\n\nShould the trader stick with their original choice of door A or switch to B?\n\nBefore reading further, give it a go. What would you do?\n\nMost people are likely to have a gut intuition that \u201cit doesn\u2019t matter\u201d arguing that in the first instance each door had a \u2153 chance of hiding the prize, and that after the host intervention \ud83c\udfa9, when only two doors remain closed, the winning of the prize is 50:50.\n\nThere are various ways of explaining why the coin toss intuition is incorrect. Most of these involve maths equations, or simulations. Whereas we will address these later, we\u2019ll attempt to solve by applying Occam\u2019s razor:\n\nA principle that states that simpler explanations are preferable to more complex ones \u2014 William of Ockham (1287\u20131347)\n\nTo do this it is instructive to slightly redefine the problem to a large N doors instead of the original three.\n\nThe Large N-Door Problem\n\nSimilar to before: you have to choose one of many doors. For illustration let\u2019s say N=100. Behind one of the doors there is the prize \ud83d\ude97 and behind 99 (N-1) of the rest are goats \ud83d\udc10.\n\nThe 100 Door Monty Hall problem before the host intervention.\n\nYou choose one door \ud83d\udc47 and the host \ud83c\udfa9 reveals 98 (N-2) of the other doors that have goats \ud83d\udc10 leaving yours \ud83d\udc47 and one more closed \ud83d\udeaa.\n\nThe 100 Door Monty Hall problem after the host intervention. Should you stick with your door \ud83d\udc47 or make the switch?\n\nShould you stick with your original choice or make the switch?\n\nI think you\u2019ll agree with me that the remaining door, not chosen by you, is much more likely to conceal the prize \u2026 so you should definitely make the switch!\n\nIt\u2019s illustrative to compare both scenarios discussed so far. In the next figure we compare the post host intervention for the N=3 setup (top panel) and that of N=100 (bottom):\n\nPost intervention settings for the N=3 setup (top) and N=100 (bottom).\n\nIn both cases we see two shut doors, one of which we\u2019ve chosen. The main difference between these scenarios is that in the first we see one goat and in the second there are more than the eye would care to see (unless you shepherd for a living).\n\nWhy do most people consider the first case as a \u201c50:50\u201d toss up and in the second it\u2019s obvious to make the switch?\n\nWe\u2019ll soon address this question of why. First let\u2019s put probabilities of success behind the different scenarios.\n\nWhat\u2019s The Frequency, Kenneth?\n\nSo far we learnt from the N=100 scenario that switching doors is obviously beneficial. Inferring for the N=3 may be a leap of faith for most. Using some basic probability arguments here we\u2019ll quantify why it is favourable to make the switch for any number door scenario N.\n\nWe start with the standard Monty Hall Problem (N=3). When it starts the probability of the prize being behind each of the doors A, B and C is p=\u2153. To be explicit let\u2019s define the Y parameter to be the door with the prize \ud83d\ude97, i.e, p(Y=A)= p(Y=B)=p(Y=C)=\u2153.\n\nThe trick to solving this problem is that once the trader\u2019s door A has been chosen \u261d\ufe0f, we should pay close attention to the set of the other doors {B,C}, which has the probability of p(Y\u2208{B,C})=p(Y=B)+p(Y=C)=\u2154. This visual may help make sense of this:\n\nBy being attentive to the {B,C} the rest should follow. When the goat \ud83d\udc10 is revealed\n\nit is apparent that the probabilities post intervention change. Note that for ease of reading I\u2019ll drop the Y notation, where p(Y=A) will read p(A) and p(Y\u2208{B,C}) will read p({B,C}). Also for completeness the full terms after the intervention should be even longer due to it being conditional, e.g, p(Y=A|Z=C), p(Y\u2208{B,C}|Z=C), where Z is a parameter representing the choice of the host \ud83c\udfa9. (In the Bayesian supplement section below I use proper notation without this shortening.)\n\np(A) remains \u2153\n\np({B,C})=p(B)+p(C) remains \u2154,\n\np(C)=0; we just learnt that the goat \ud83d\udc10 is behind door C, not the prize.\n\np(B)= p({B,C})-p(C) = \u2154\n\nFor anyone with the information provided by the host (meaning the trader and the audience) this means that it isn\u2019t a toss of a fair coin! For them the fact that p(C) became zero does not \u201craise all other boats\u201d (probabilities of doors A and B), but rather p(A) remains the same and p(B) gets doubled.\n\nThe bottom line is that the trader should consider p(A) = \u2153 and p(B)=\u2154, hence by switching they are doubling the odds at winning!\n\nLet\u2019s generalise to N (to make the visual simpler we\u2019ll use N=100 again as an analogy).\n\nWhen we start all doors have odds of winning the prize p=1/N. After the trader chooses one door which we\u2019ll call D\u2081, meaning p(Y=D\u2081)=1/N, we should now pay attention to the remaining set of doors {D\u2082, \u2026, D\u2099} will have a chance of p(Y\u2208{D\u2082, \u2026, D\u2099})=(N-1)/N.\n\nWhen the host reveals (N-2) doors {D\u2083, \u2026, D\u2099} with goats (back to short notation):\n\np(D\u2081) remains 1/N\n\np({D\u2082, \u2026, D\u2099})=p(D\u2082)+p(D\u2083)+\u2026 + p(D\u2099) remains (N-1)/N\n\np(D\u2083)=p(D\u2084)= \u2026=p(D\u2099\u208b\u2081) =p(D\u2099) = 0; we just learnt that they have goats, not the prize.\n\np(D\u2082)=p({D\u2082, \u2026, D\u2099}) \u2014 p(D\u2083) \u2014 \u2026 \u2014 p(D\u2099)=(N-1)/N\n\nThe trader should now consider two door values p(D\u2081)=1/N and p(D\u2082)=(N-1)/N.\n\nHence the odds of winning improved by a factor of N-1! In the case of N=100, this means by an odds ratio of 99! (i.e, 99% likely to win a prize when switching vs. 1% if not).\n\nThe improvement of odds ratios in all scenarios between N=3 to 100 may be seen in the following graph. The thin line is the probability of winning by choosing any door prior to the intervention p(Y)=1/N. Note that it also represents the chance of winning after the intervention, if they decide to stick to their guns and not switch p(Y=D\u2081|Z={D\u2083\u2026D\u2099}). (Here I reintroduce the more rigorous conditional form mentioned earlier.) The thick line is the probability of winning the prize after the intervention if the door is switched p(Y=D\u2082|Z={D\u2083\u2026D\u2099})=(N-1)/N:\n\nProbability of winning as a function of N. p(Y)=p(Y=no switch|Z)=1/N is the thin line; p(Y=switch|Z)=N/(N-1) is the thick one. (By definition the sum of both lines is 1 for each N.)\n\nPerhaps the most interesting aspect of this graph (albeit also by definition) is that the N=3 case has the highest probability before the host intervention \ud83c\udfa9, but the lowest probability after and vice versa for N=100.\n\nAnother interesting feature is the quick climb in the probability of winning for the switchers:\n\nN=3: p=67%\n\nN=4: p=75%\n\nN=5=80%\n\nThe switchers curve gradually reaches an asymptote approaching at 100% whereas at N=99 it is 98.99% and at N=100 is equal to 99%.\n\nThis starts to address an interesting question:\n\nWhy Is Switching Obvious For Large N But Not N=3?\n\nThe answer is the fact that this puzzle is slightly ambiguous. Only the highly attentive realise that by revealing the goat (and never the prize!) the host is actually conveying a lot of information that should be incorporated into one\u2019s calculation. Later we discuss the difference of doing this calculation in one\u2019s mind based on intuition and slowing down by putting pen to paper or coding up the problem.\n\nHow much information is conveyed by the host by intervening?\n\nA hand wavy explanation \ud83d\udc4b \ud83d\udc4b is that this information may be visualised as the gap between the lines in the graph above. For N=3 we saw that the odds of winning doubled (nothing to sneeze at!), but that doesn\u2019t register as strongly to our common sense intuition as the 99 factor as in the N=100.\n\nI have also considered describing stronger arguments from Information Theory that provide useful vocabulary to express communication of information. However, I feel that this fascinating field deserves a post of its own, which I\u2019ve published.\n\nThe main takeaway for the Monty Hall problem is that I have calculated the information gain to be a logarithmic function of the number of doors c using this formula:\n\nInformation Gain due to the intervention of the host \ud83c\udfa9 for a setup with c doors. Full details in my upcoming article.\n\nFor c=3 door case, e.g, the information gain is \u2154 bits (of a maximum possible 1.58 bits). Full details are in this article on entropy.\n\nTo summarise this section, we use basic probability arguments to quantify the probabilities of winning the prize showing the benefit of switching for all N door scenarios. For those interested in more formal solutions \u2694\ufe0f using Bayesian and Causality on the bottom I provide supplement sections.\n\nIn the next three final sections we\u2019ll discuss how this problem was accepted in the general public back in the 1990s, discuss lessons learnt and then summarise how we can apply them in real-world settings.\n\nBeing Confused Is OK \ud83d\ude15\n\n\u201cNo, that is impossible, it should make no difference.\u201d \u2014 Paul Erd\u0151s\n\nIf you still don\u2019t feel comfortable with the solution of the N=3 Monty Hall problem, don\u2019t worry you are in good company! According to Vazsonyi (1999)\u00b9 even Paul Erd\u0151s who is considered \u201cof the greatest experts in probability theory\u201d was confounded until computer simulations were demonstrated to him.\n\nWhen the original solution by Steve Selvin (1975)\u00b2 was popularised by Marilyn vos Savant in her column \u201cAsk Marilyn\u201d in Parade magazine in 1990 many readers wrote that Selvin and Savant were wrong\u00b3. According to Tierney\u2019s 1991 article in the New York Times, this included about 10,000 readers, including nearly 1,000 with Ph.D degrees\u2074.\n\nOn a personal note, over a decade ago I was exposed to the standard N=3 problem and since then managed to forget the solution numerous times. When I learnt about the large N approach I was quite excited about how intuitive it was. I then failed to explain it to my technical manager over lunch, so this is an attempt to compensate. I still have the same day job \ud83d\ude42.\n\nWhile researching this piece I realised that there is a lot to learn in terms of decision making in general and in particular useful for data science.\n\nLessons Learnt From Monty Hall Problem\n\nIn his book Thinking Fast and Slow, the late Daniel Kahneman, the co-creator of Behaviour Economics, suggested that we have two types of thought processes:\n\nSystem 1 \u2014 fast thinking \ud83d\udc07: based on intuition. This helps us react fast with confidence to familiar situations.\n\nSystem 2 \u2013 slow thinking \ud83d\udc22: based on deep thought. This helps figure out new complex situations that life throws at us.\n\nAssuming this premise, you might have noticed that in the above you were applying both.\n\nBy examining the visual of N=100 doors your System 1 \ud83d\udc07 kicked in and you immediately knew the answer. I\u2019m guessing that in the N=3 you were straddling between System 1 and 2. Considering that you had to stop and think a bit when going throughout the probabilities exercise it was definitely System 2 \ud83d\udc22.\n\nThe decision maker\u2019s struggle between System 1 \ud83d\udc30 and System 2 \ud83d\udc22. Generated using Gemini Imagen 3\n\nBeyond the fast and slow thinking I feel that there are a lot of data decision making lessons that may be learnt.\n\n(1) Assessing probabilities can be counter-intuitive \u2026\n\nor\n\nBe comfortable with shifting to deep thought \ud83d\udc22\n\nWe\u2019ve clearly shown that in the N=3 case. As previously mentioned it confounded many people including prominent statisticians.\n\nAnother classic example is The Birthday Paradox \ud83e\udd73\ud83c\udf82, which shows how we underestimate the likelihood of coincidences. In this problem most people would think that one needs a large group of people until they find a pair sharing the same birthday. It turns out that all you need is 23 to have a 50% chance. And 70 for a 99.9% chance.\n\nOne of the most confusing paradoxes in the realm of data analysis is Simpson\u2019s, which I detailed in a previous article. This is a situation where trends of a population may be reversed in its subpopulations.\n\nThe common with all these paradoxes is them requiring us to get comfortable to shifting gears \u2699\ufe0f from System 1 fast thinking \ud83d\udc07 to System 2 slow \ud83d\udc22. This is also the common theme for the lessons outlined below.\n\nA few more classical examples are: The Gambler\u2019s Fallacy \ud83c\udfb2, Base Rate Fallacy \ud83e\ude7a and the The Linda [bank teller] Problem \ud83c\udfe6. These are beyond the scope of this article, but I highly recommend looking them up to further sharpen ways of thinking about data.\n\n(2) \u2026 especially when dealing with ambiguity\n\nor\n\nSearch for clarity in ambiguity \ud83d\udd0e\n\nLet\u2019s reread the problem, this time as stated in \u201cAsk Marilyn\u201d\n\nSuppose you\u2019re on a game show, and you\u2019re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say \u21161, and the host, who knows what\u2019s behind the doors, opens another door, say \u21163, which has a goat. He then says to you, \u201cDo you want to pick door \u21162?\u201d Is it to your advantage to switch your choice?\n\nWe discussed that the most important piece of information is not made explicit. It says that the host \u201cknows what\u2019s behind the doors\u201d, but not that they open a door at random, although it\u2019s implicitly understood that the host will never open the door with the car.\n\nMany real life problems in data science involve dealing with ambiguous demands as well as in data provided by stakeholders.\n\nIt is crucial for the researcher to track down any relevant piece of information that is likely to have an impact and update that into the solution. Statisticians refer to this as \u201cbelief update\u201d.\n\n(3) With new information we should update our beliefs \ud83d\udd01\n\nThis is the main aspect separating the Bayesian stream of thought to the Frequentist. The Frequentist approach takes data at face value (referred to as flat priors). The Bayesian approach incorporates prior beliefs and updates it when new findings are introduced. This is especially useful when dealing with ambiguous situations.\n\nTo drive this point home, let\u2019s re-examine this figure comparing between the post intervention N=3 setups (top panel) and the N=100 one (bottom panel).\n\nCopied from above. Post intervention settings for the N=3 setup (top) and N=100 (bottom).\n\nIn both cases we had a prior belief that all doors had an equal chance of winning the prize p=1/N.\n\nOnce the host opened one door (N=3; or 98 doors when N=100) a lot of valuable information was revealed whereas in the case of N=100 it was much more apparent than N=3.\n\nIn the Frequentist approach, however, most of this information would be ignored, as it only focuses on the two closed doors. The Frequentist conclusion, hence is a 50% chance to win the prize regardless of what else is known about the situation. Hence the Frequentist takes Paul Erd\u0151s\u2019 \u201cno difference\u201d point of view, which we now know to be incorrect.\n\nThis would be reasonable if all that was presented were the two doors and not the intervention and the goats. However, if that information is presented, one should shift gears into System 2 thinking and update their beliefs in the system. This is what we have done by focusing not only on the shut door, but rather consider what was learnt about the system at large.\n\nFor the brave hearted \u2694\ufe0f, in a supplementary section below called The Bayesian Point of View I solve for the Monty Hall problem using the Bayesian formalism.\n\n(4) Be one with subjectivity \ud83e\uddd8\n\nThe Frequentist main reservation about \u201cgoing Bayes\u201d is that \u2014 \u201cStatistics should be objective\u201d.\n\nThe Bayesian response is \u2014 the Frequentist\u2019s also apply a prior without realising it \u2014 a flat one.\n\nRegardless of the Bayesian/Frequentist debate, as researchers we try our best to be as objective as possible in every step of the analysis.\n\nThat said, it is inevitable that subjective decisions are made throughout.\n\nE.g, in a skewed distribution should one quote the mean or median? It highly depends on the context and hence a subjective decision needs to be made.\n\nThe responsibility of the analyst is to provide justification for their choices first to convince themselves and then their stakeholders.\n\n(5) When confused \u2014 look for a useful analogy\n\n\u2026 but tread with caution \u26a0\ufe0f\n\nWe saw that by going from the N=3 setup to the N=100 the solution was apparent. This is a trick scientists frequently use \u2014 if the problem appears at first a bit too confusing/overwhelming, break it down and try to find a useful analogy.\n\nIt is probably not a perfect comparison, but going from the N=3 setup to N=100 is like examining a picture from up close and zooming out to see the big picture. Think of having only a puzzle piece \ud83e\udde9 and then glancing at the jigsaw photo on the box.\n\nMonty Hall in 1976. Credit: Wikipedia and using Visual Paradigm Online for the puzzle effect\n\nNote: whereas analogies may be powerful, one should do so with caution, not to oversimplify. Physicists refer to this situation as the spherical cow \ud83d\udc2e method, where models may oversimplify complex phenomena.\n\nI admit that even with years of experience in applied statistics at times I still get confused at which method to apply. A large part of my thought process is identifying analogies to known solved problems. Sometimes after making progress in a direction I will realise that my assumptions were wrong and seek a new direction. I used to quip with colleagues that they shouldn\u2019t trust me before my third attempt \u2026\n\n(6) Simulations are powerful but not always necessary \ud83e\udd16\n\nIt\u2019s interesting to learn that Paul Erd\u0151s and other mathematicians were convinced only after seeing simulations of the problem.\n\nI am two-minded about usage of simulations when it comes to problem solving.\n\nOn the one hand simulations are powerful tools to analyse complex and intractable problems. Especially in real life data in which one wants a grasp not only of the underlying formulation, but also stochasticity.\n\nAnd here is the big BUT \u2014 if a problem can be analytically solved like the Monty Hall one, simulations as fun as they may be (such as the MythBusters have done\u2076), may not be necessary.\n\nAccording to Occam\u2019s razor, all that is required is a brief intuition to explain the phenomena. This is what I attempted to do here by applying common sense and some basic probability reasoning. For those who enjoy deep dives I provide below supplementary sections with two methods for analytical solutions \u2014 one using Bayesian statistics and another using Causality.\n\n[Update] After publishing the first version of this article there was a comment that Savant\u2019s solution\u00b3 may be simpler than those presented here. I revisited her communications and agreed that it should be added. In the process I realised three more lessons may be learnt.\n\n(7) A well designed visual goes a long way \ud83c\udfa8\n\nContinuing the principle of Occam\u2019s razor, Savant explained\u00b3 quite convincingly in my opinion:\n\nYou should switch. The first door has a 1/3 chance of winning, but the second door has a 2/3 chance. Here\u2019s a good way to visualize what happened. Suppose there are a million doors, and you pick door #1. Then the host, who knows what\u2019s behind the doors and will always avoid the one with the prize, opens them all except door #777,777. You\u2019d switch to that door pretty fast, wouldn\u2019t you?\n\nHence she provided an abstract visual for the readers. I attempted to do the same with the 100 doors figures.\n\nMarilyn vos Savant who popularised the Monty Hall Problem. Credit: Ben David on Flickr under license\n\nAs mentioned many readers, and especially with backgrounds in maths and statistics, still weren\u2019t convinced.\n\nShe revised\u00b3 with another mental image:\n\nThe benefits of switching are readily proven by playing through the six games that exhaust all the possibilities. For the first three games, you choose #1 and \u201cswitch\u201d each time, for the second three games, you choose #1 and \u201cstay\u201d each time, and the host always opens a loser. Here are the results.\n\nShe added a table with all the scenarios. I took some artistic liberty and created the following figure. As indicated, the top batch are the scenarios in which the trader switches and the bottom when they switch. Lines in green are games which the trader wins, and in red when they get zonked. The \ud83d\udc47 symbolised the door chosen by the trader and Monte Hall then chooses a different door that has a goat \ud83d\udc10 behind it.\n\nAdaptation of Savant\u2019s table\u00b3 of six scenarios that shows the solution to the Monty Hall Problem\n\nWe clearly see from this diagram that the switcher has a \u2154 chance of winning and those that stay only \u2153.\n\nThis is yet another elegant visualisation that clearly explains the non intuitive.\n\nIt strengthens the claim that there is no real need for simulations in this case because all they would be doing is rerunning these six scenarios.\n\nOne more popular solution is decision tree illustrations. You can find these in the Wikipedia page, but I find it\u2019s a bit redundant to Savant\u2019s table.\n\nThe fact that we can solve this problem in so many ways yields another lesson:\n\n(8) There are many ways to skin a \u2026 problem \ud83d\udc08\n\nOf the many lessons that I have learnt from the writings of late Richard Feynman, one of the best physics and ideas communicators, is that a problem can be solved many ways. Mathematicians and Physicists do this all the time.\n\nA relevant quote that paraphrases Occam\u2019s razor:\n\nIf you can\u2019t explain it simply, you don\u2019t understand it well enough \u2014 attributed to Albert Einstein\n\nAnd finally\n\n(9) Embrace ignorance and be humble \ud83e\udd37\u200d\u2642\n\n\u201cYou are utterly incorrect \u2026 How many irate mathematicians are needed to get you to change your mind?\u201d \u2014 Ph.D from Georgetown University\n\n\u201cMay I suggest that you obtain and refer to a standard textbook on probability before you try to answer a question of this type again?\u201d \u2014 Ph.D from University of Florida\n\n\u201cYou\u2019re in error, but Albert Einstein earned a dearer place in the hearts of people after he admitted his errors.\u201d \u2014 Ph.D. from University of Michigan\n\nOuch!\n\nThese are some of the said responses from mathematicians to the Parade article.\n\nSuch unnecessary viciousness.\n\nYou can check the reference\u00b3 to see the writer\u2019s names and other like it. To whet your appetite: \u201cYou blew it, and you blew it big!\u201d, , \u201cYou made a mistake, but look at the positive side. If all those Ph.D.\u2019s were wrong, the country would be in some very serious trouble.\u201d, \u201cI am in shock that after being corrected by at least three mathematicians, you still do not see your mistake.\u201d.\n\nAnd as expected from the 1990s perhaps the most embarrassing one was from a resident of Oregon:\n\n\u201cMaybe women look at math problems differently than men.\u201d\n\nThese make me cringe and be embarrassed to be associated by gender and Ph.D. title with these graduates and professors.\n\nHopefully in the 2020s most people are more humble about their ignorance. Yuval Noah Harari discusses the fact that the Scientific Revolution of Galileo Galilei et al. was not due to knowledge but rather admittance of ignorance.\n\n\u201cThe great discovery that launched the Scientific Revolution was the discovery that humans do not know the answers to their most important questions\u201d \u2014 Yuval Noah Harari\n\nFortunately for mathematicians\u2019 image, there were also quiet a lot of more enlightened comments. I like this one from one Seth Kalson, Ph.D. of MIT:\n\nYou are indeed correct. My colleagues at work had a ball with this problem, and I dare say that most of them, including me at first, thought you were wrong!\n\nWe\u2019ll summarise by examining how, and if, the Monty Hall problem may be applied in real-world settings, so you can try to relate to projects that you are working on.\n\nApplication in Real World Settings\n\nfor this article I found that beyond artificial setups for entertainment\u2076 \u2077 there aren\u2019t practical settings for this problem to use as an analogy. Of course, I may be wrong\u2078 and would be glad to hear if you know of one.\n\nOne way of assessing the viability of an analogy is using arguments from causality which provides vocabulary that cannot be expressed with standard statistics.\n\nIn a previous post I discussed the fact that the story behind the data is as important as the data itself. In particular Causal Graph Models visualise the story behind the data, which we will use as a framework for a reasonable analogy.\n\nFor the Monty Hall problem we can build a Causal Graph Model like this:\n\nReading:\n\nThe door chosen by the trader\u261d\ufe0f is independent from that with the prize \ud83d\ude97 and vice versa. As important, there is no common cause between them that might generate a spurious correlation.\n\nThe host\u2019s choice \ud83c\udfa9 depends on both \u261d\ufe0f and \ud83d\ude97.\n\nBy comparing causal graphs of two systems one can get a sense for how analogous both are. A perfect analogy would require more details, but this is beyond the scope of this article. Briefly, one would want to ensure similar functions between the parameters (referred to as the Structural Causal Model; for details see in the supplementary section below called \u27a1\ufe0f The Causal Point of View).\n\nThose interested in learning further details about using Causal Graphs Models to assess causality in real world problems may be interested in this article.\n\nAnecdotally it is also worth mentioning that on Let\u2019s Make a Deal, Monty himself has admitted years later to be playing mind games with the contestants and did not always follow the rules, e.g, not always doing the intervention as \u201cit all depends on his mood\u201d\u2074.\n\nIn our setup we assumed perfect conditions, i.e., a host that does not skew from the script and/or play on the trader\u2019s emotions. Taking this into consideration would require updating the Graphical Model above, which is beyond the scope of this article.\n\nSome might be disheartened to realise at this stage of the post that there might not be real world applications for this problem.\n\nI argue that lessons learnt from the Monty Hall problem definitely are.\n\nJust to summarise them again:\n\n(1) Assessing probabilities can be counter intuitive \u2026\n\n(Be comfortable with shifting to deep thought \ud83d\udc22)\n\n(2) \u2026 especially when dealing with ambiguity\n\n(Search for clarity \ud83d\udd0e)\n\n(3) With new information we should update our beliefs \ud83d\udd01\n\n(4) Be one with subjectivity \ud83e\uddd8\n\n(5) When confused \u2014 look for a useful analogy \u2026 but tread with caution \u26a0\ufe0f\n\n(6) Simulations are powerful but not always necessary \ud83e\udd16\n\n(7) A well designed visual goes a long way \ud83c\udfa8\n\n(8) There are many ways to skin a \u2026 problem \ud83d\udc08\n\n(9) Embrace ignorance and be humble \ud83e\udd37\u200d\u2642\n\nWhile the Monty Hall Problem might seem like a simple puzzle, it offers valuable insights into decision-making, particularly for data scientists. The problem highlights the importance of going beyond intuition and embracing a more analytical, data-driven approach. By understanding the principles of Bayesian thinking and updating our beliefs based on new information, we can make more informed decisions in many aspects of our lives, including data science. The Monty Hall Problem serves as a reminder that even seemingly straightforward scenarios can contain hidden complexities and that by carefully examining available information, we can uncover hidden truths and make better decisions.\n\nAt the bottom of the article I provide a list of resources that I found useful to learn about this topic.\n\nLoved this post? \ud83d\udc8c Join me on LinkedIn or \u2615 Buy me a coffee!\n\nCredits\n\nUnless otherwise noted, all images were created by the author.\n\nMany thanks to Jim Parr, Will Reynolds, and Betty Kazin for their useful comments.\n\nIn the following supplementary sections \u2694\ufe0f I derive solutions to the Monty Hall\u2019s problem from two perspectives:\n\nBayesian\n\nCausal\n\nBoth are motivated by questions in textbook: Causal Inference in Statistics A Primer by Judea Pearl, Madelyn Glymour, and Nicholas P. Jewell (2016).\n\nSupplement 1: The Bayesian Point of View\n\nThis section assumes a basic understanding of Bayes\u2019 Theorem, in particular being comfortable conditional probabilities. In other words if this makes sense:\n\nWe set out to use Bayes\u2019 theorem to prove that switching doors improves chances in the N=3 Monty Hall Problem. (Problem 1.3.3 of the Primer textbook.)\n\nWe define\n\nX \u2014 the chosen door \u261d\ufe0f\n\nY\u2014 the door with the prize \ud83d\ude97\n\nZ \u2014 the door opened by the host \ud83c\udfa9\n\nLabelling the doors as A, B and C, without loss of generality, we need to solve for:\n\nUsing Bayes\u2019 theorem we equate the left side as\n\nand the right one as:\n\nMost components are equal (remember that P(Y=A)=P(Y=B)=\u2153 so we are left to prove:\n\nIn the case where Y=B (the prize \ud83d\ude97 is behind door B \ud83d\udeaa), the host has only one choice (can only select door C \ud83d\udeaa), making P(X=A, Z=C|Y=B)= 1.\n\nIn the case where Y=A (the prize \ud83d\ude97 is behind door A \u261d\ufe0f), the host has two choices (doors B \ud83d\udeaa and C \ud83d\udeaa) , making P(X=A, Z=C|Y=A)= 1/2.\n\nFrom here:\n\nQuod erat demonstrandum.\n\nNote: if the \u201chost choices\u201d arguments didn\u2019t make sense look at the table below showing this explicitly. You will want to compare entries {X=A, Y=B, Z=C} and {X=A, Y=A, Z=C}.\n\nSupplement 2: The Causal Point of View \u27a1\ufe0f\n\nThe section assumes a basic understanding of Directed Acyclic Graphs (DAGs) and Structural Causal Models (SCMs) is useful, but not required. In brief:\n\nDAGs qualitatively visualise the causal relationships between the parameter nodes.\n\nSCMs quantitatively express the formula relationships between the parameters.\n\nGiven the DAG\n\nwe are going to define the SCM that corresponds to the classic N=3 Monty Hall problem and use it to describe the joint distribution of all variables. We later will generically expand to N. (Inspired by problem 1.5.4 of the Primer textbook as well as its brief mention of the N door problem.)\n\nWe define\n\nX \u2014 the chosen door \u261d\ufe0f\n\nY \u2014 the door with the prize \ud83d\ude97\n\nZ \u2014 the door opened by the host \ud83c\udfa9\n\nAccording to the DAG we see that according to the chain rule:\n\nThe SCM is defined by exogenous variables U , endogenous variables V, and the functions between them F:\n\nU = {X,Y}, V={Z}, F= {f(Z)}\n\nwhere X, Y and Z have door values:\n\nD = {A, B, C}\n\nThe host choice \ud83c\udfa9 is f(Z) defined as:\n\nIn order to generalise to N doors, the DAG remains the same, but the SCM requires to update D to be a set of N doors D\u1d62: {D\u2081, D\u2082, \u2026 D\u2099}.\n\nExploring Example Scenarios\n\nTo gain an intuition for this SCM, let\u2019s examine 6 examples of 27 (=3\u00b3) :\n\nWhen X=Y (i.e., the prize \ud83d\ude97 is behind the chosen door \u261d\ufe0f)\n\nP(Z=A|X=A, Y=A) = 0; \ud83c\udfa9 cannot choose the participant\u2019s door \u261d\ufe0f\n\nP(Z=B|X=A, Y=A) = 1/2; \ud83d\ude97 is behind \u261d\ufe0f \u2192 \ud83c\udfa9 chooses B at 50%\n\nP(Z=C|X=A, Y=A) = 1/2; \ud83d\ude97 is behind \u261d\ufe0f \u2192 \ud83c\udfa9 chooses C at 50%\n\n(complementary to the above)\n\nWhen X\u2260Y (i.e., the prize \ud83d\ude97 is not behind the chosen door \u261d\ufe0f)\n\nP(Z=A|X=A, Y=B) = 0; \ud83c\udfa9 cannot choose the participant\u2019s door \u261d\ufe0f\n\nP(Z=B|X=A, Y=B) = 0; \ud83c\udfa9 cannot choose prize door \ud83d\ude97\n\nP(Z=C|X=A, Y=B) = 1; \ud83c\udfa9 has not choice in the matter\n\n(complementary to the above)\n\nCalculating Joint Probabilities\n\nUsing logic let\u2019s code up all 27 possibilities in python \ud83d\udc0d\n\ndf = pd.DataFrame({\"X\": ([\"A\"] * 9) + ([\"B\"] * 9) + ([\"C\"] * 9), \"Y\": (([\"A\"] * 3) + ([\"B\"] * 3) + ([\"C\"] * 3) )* 3, \"Z\": [\"A\", \"B\", \"C\"] * 9}) df[\"P(Z|X,Y)\"] = None p_x = 1./3 p_y = 1./3 df.loc[df.query(\"X == Y == Z\").index, \"P(Z|X,Y)\"] = 0 df.loc[df.query(\"X == Y != Z\").index, \"P(Z|X,Y)\"] = 0.5 df.loc[df.query(\"X != Y == Z\").index, \"P(Z|X,Y)\"] = 0 df.loc[df.query(\"Z == X != Y\").index, \"P(Z|X,Y)\"] = 0 df.loc[df.query(\"X != Y\").query(\"Z != Y\").query(\"Z != X\").index, \"P(Z|X,Y)\"] = 1 df[\"P(X, Y, Z)\"] = df[\"P(Z|X,Y)\"] * p_x * p_y print(f\"Testing normalisation of P(X,Y,Z) {df['P(X, Y, Z)'].sum()}\") df\n\nyields\n\nResources\n\nThis Quora discussion by Joshua Engel helped me shape a few aspects of this article.\n\nCausal Inference in Statistics A Primer / Pearl, Glymour & Jewell (2016) \u2014 excellent short text book (site)\n\nI also very much enjoy Tim Harford\u2019s podcast Cautionary Tales. He wrote about this topic on November 3rd 2017 for the Financial Times: Monty Hall and the game show stick-or-switch conundrum\n\nFootnotes\n\n\u00b9 Vazsonyi, Andrew (December 1998 \u2014 January 1999). \u201cWhich Door Has the Cadillac?\u201d (PDF). Decision Line: 17\u201319. Archived from the original (PDF) on 13 April 2014. Retrieved 16 October 2012.\n\n\u00b2 Steve Selvin to the American Statistician in 1975.[1][2]\n\n\u00b3Game Show Problem by Marilyn vos Savant\u2019s \u201cAsk Marilyn\u201d in marilynvossavant.com (web archive): \u201cThis material in this article was originally published in PARADE magazine in 1990 and 1991\u201d\n\n\u2074Tierney, John (21 July 1991). \u201cBehind Monty Hall\u2019s Doors: Puzzle, Debate and Answer?\u201d. The New York Times. Retrieved 18 January 2008.\n\n\u2075 Kahneman, D. (2011). Thinking, fast and slow. Farrar, Straus and Giroux.\n\n\u2076 MythBusters Episode 177 \u201cPick a Door\u201d (Wikipedia) \ud83e\udd21 Watch Mythbuster\u2019s approach\n\n\u2076Monty Hall Problem on Survivor Season 41 (LinkedIn, YouTube) \ud83e\udd21 Watch Survivor\u2019s take on the problem\n\n\u2077 Jingyi Jessica Li (2024) How the Monty Hall problem is similar to the false discovery rate in high-throughput data analysis.\n\nWhereas the author points about \u201csimilarities\u201d between hypothesis testing and the Monty Hall problem, I think that this is a bit misleading. The author is correct that both problems change by the order in which processes are done, but that is part of Bayesian statistics in general, not limited to the Monty Hall problem."}