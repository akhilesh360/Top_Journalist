{"url": "https://techcrunch.com/2022/12/20/petals-is-creating-a-free-distributed-network-for-running-text-generating-ai/", "title": "Petals is creating a free, distributed network for running text-generating AI", "authors": ["Kyle Wiggers", "Ai Editor", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media", "Min-Width", "--C-Author-Card-Image-Size", "Img.Wp-Block-Tc_Author-Card__Image Height Var --C-Author-Card-Image-Size", "Width Var --C-Author-Card-Image-Size", "Img.Wp-Block-Tc_Author-Card__Image Border-Radius", "Max-Width None -O-Object-Fit Cover Object-Fit Cover Display Block"], "publication_date": "2022-12-20T00:00:00", "text": "BigScience, a community project backed by startup Hugging Face with the goal of making text-generating AI widely available, is developing a system called Petals that can run AI like ChatGPT by joining resources from people across the internet. With Petals, the code for which was released publicly last month, volunteers can donate their hardware power to tackle a portion of a text-generating workload and team up others to complete larger tasks, similar to Folding@home and other distributed compute setups.\n\n\u201cPetals is an ongoing collaborative project from researchers at Hugging Face, Yandex Research and the University of Washington,\u201d Alexander Borzunov, the lead developer of Petals and a research engineer at Yandex, told TechCrunch in an email interview. \u201cUnlike \u2026 APIs that are typically less flexible, Petals is entirely open source, so researchers may integrate latest text generation and system adaptation methods not yet available in APIs or access the system\u2019s internal states to study its features.\u201d\n\nOpen source, but not free\n\nFor all its faults, text-generating AI such as ChatGPT can be quite useful \u2014 at least if the viral demos on social media are anything to go by. ChatGPT and its kin promise to automate some of the mundane work that typically bogs down programmers, writers and even data scientists by generating human-like code, text and formulas at scale.\n\nBut they\u2019re expensive to run. According to one estimate, ChatGPT is costing its developer, OpenAI, $100,000 per day, which works out to an eye-watering $3 million per month.\n\nThe costs involved with running cutting-edge text-generating AI have kept it relegated to startups and AI labs with substantial financial backing. It\u2019s no coincidence that the companies offering some of the more capable text-generating systems tech, including AI21 Labs, Cohere and the aforementioned OpenAI, have raised hundreds of millions of dollars in capital from VCs.\n\nBut Petals democratizes things \u2014 in theory. Inspired by Borzunov\u2019s earlier work focused on training AI systems over the internet, Petals aims to drastically bring down the costs of running text-generating AI.\n\n\u201cPetals is a first step towards enabling truly collaborative and continual improvement of machine learning models,\u201d Colin Raffel, a faculty researcher at Hugging Face, told TechCrunch via email. \u201cIt \u2026 marks an ongoing shift from large models mostly confined to supercomputers to something more broadly accessible.\u201d\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nRaffel made reference to the gold rush, of sorts, that\u2019s occurred over the past year in the open source text generation community. Thanks to volunteer efforts and the generosity of tech giants\u2019 research labs, the type of bleeding-edge text-generating AI that was once beyond reach of small-time developers suddenly became available, trained and ready to deploy.\n\nBigScience debuted Bloom, a language model in many ways on par with OpenAI\u2019s GPT-3 (the progenitor of ChatGPT), while Meta open sourced a comparably powerful AI system called OPT. Meanwhile, Microsoft and Nvidia partnered to make available one of the largest language systems ever developed, MT-NLG.\n\nBut all these systems require powerful hardware to use. For example, running Bloom on a local machine requires a GPU retailing in the hundreds to thousands of dollars. Enter the Petals network, which Borzunov claims will be powerful enough to run and fine-tune AI systems for chatbots and other \u201cinteractive\u201d apps once it reaches sufficient capacity. To use Petals, users install an open source library and visit a website that provides instructions to connect to the Petals network. After they\u2019re connected, they can generate text from Bloom running on Petals, or create a Petals server to contribute compute back to the network.\n\nThe more servers, the more robust the network. If one server goes down, Petals attempts to find a replacement automatically. While servers disconnect after around 1.5 seconds of inactivity to save on resources, Borzunov says that Petals is smart enough to quickly resume sessions, leading to only a slight delay for end-users.\n\nIn my tests, generating text using Petals took anywhere between a couple of seconds for basic prompts (e.g. \u201cTranslate the word \u2018cat\u2019 to Spanish\u201d) to well over 20 seconds for more complex requests (e.g. \u201cWrite an essay in the style of Diderot about the nature of the universe\u201d). One prompt (\u201cExplain the meaning of life\u201d) took close to three minutes, but to be fair, I instructed the system to respond with a wordier answer (around 75 words) than the previous few.\n\nThat\u2019s noticeably slower than ChatGPT \u2014 but also free. While ChatGPT doesn\u2019t cost anything today, there\u2019s no guarantee that that\u2019ll be true in the future.\n\nBorzunov wouldn\u2019t reveal how large the Petals network is currently, save that \u201cmultiple\u201d users with \u201cGPUs of different capacity\u201d have joined it since its launch in early December. The goal is to eventually introduce a rewards system to incentivize people to donate their compute; donators will receive \u201cBloom points\u201d that they can spend on \u201chigher priority or increased security guarantees\u201d or potentially exchange for other rewards, Borzunov said.\n\nLimitations of distributed compute\n\nPetals promises to provide a low-cost, if not completely free, alternative to the paid text-generating services offered by vendors like OpenAI. But major technical kinks have yet to be ironed out.\n\nMost concerning are the security flaws. The GitHub page for the Petals project notes that, because of the way Petals works, it\u2019s possible for servers to recover input text \u2014 including text meant to be private \u2014 and record and modify it in a malicious way. That might entail sharing sensitive data with other users in the network, like names and phone numbers, or tweaking generated code so that it\u2019s intentionally broken.\n\nPetals also doesn\u2019t address any of the flaws inherent in today\u2019s leading text-generating systems, like their tendency to generate toxic and biased text (see the \u201cLimitations\u201d section in the Bloom entry on Hugging Face\u2019s repository). In an email interview, Max Ryabinin, the senior research scientist at Yandex Research, made it clear that Petals is intended for research and academic use \u2014 at least at present.\n\n\u201cPetals sends intermediate \u2026 data though the public network, so we ask not to use it for sensitive data because other peers may (in theory) recover them from the intermediate representations,\u201d Ryabinin said. \u201cWe suggest people who\u2019d like to use Petals for sensitive data to set up their own private swarm hosted by orgs and people they trust who are authorized to process this data. For example, several small startups and labs may collaborate and set up a private swarm to protect their data from others while still getting benefits of using Petals.\u201d\n\nAs with any distributed system, Petals could also be abused by end-users, either by bad actors looking to generate toxic text (e.g. hate speech) or developers with particularly resource-intensive apps. Raffel acknowledges that Petals will inevitably \u201cface some issues\u201d at the start. But he believes that the mission \u2014 lowering the barrier to running text-generating systems \u2014 will be well worth the initial bumps in the road.\n\n\u201cGiven the recent success of many community-organized efforts in machine learning, we believe that it is important to continue developing these tools and hope that Petals will inspire other decentralized deep learning projects,\u201d Raffel said."}