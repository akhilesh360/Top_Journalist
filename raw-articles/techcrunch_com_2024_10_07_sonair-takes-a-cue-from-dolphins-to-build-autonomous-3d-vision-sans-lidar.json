{"url": "https://techcrunch.com/2024/10/07/sonair-takes-a-cue-from-dolphins-to-build-autonomous-3d-vision-sans-lidar/", "title": "Exclusive: Sonair takes a cue from dolphins to build autonomous 3D vision without lidar", "authors": ["Ingrid Lunden", "Europe Editor", "Kyle Wiggers", "Amanda Silberling", "Rebecca Bellan", "Lorenzo Franceschi-Bicchierai", "Sean O'Kane", "Kirsten Korosec", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media"], "publication_date": "2024-10-07T00:00:00", "text": "Ultrasound is perhaps best known as the technology that enables noninvasive body scans and underwater communication and can help us park our cars. A young startup called Sonair out of Norway wants to employ it for something else: 3D computer vision used in autonomous hardware applications.\n\nSonair\u2019s founder and CEO Knut Sandven believes the company\u2019s application of ultrasound technology \u2014 a groundbreaking approach that reads sound waves to detect people and objects in 3D, with minimal energy and computational requirements \u2014 can be the basis of more useful and considerably less expensive solutions than today\u2019s more standard approach using lidar.\n\nNow, in news shared exclusively with TechCrunch, Sonair has now raised $6.8 million in funding from early-stage specialists Skyfall and RunwayFBU, along with earlier investors, and is rolling out early access to its tech. Initially, it will be aimed at autonomous mobile robot developers, but its vision (heh) is to see it being used in other applications.\n\n\u201cOur go-to-market plan is to start with robots, specifically autonomous mobile robots [AMRs] \u2014 moving stuff from A to B,\u201d Sandven said. \u201cWe are starting indoors \u2014 a limitation to give us focus, [but] we will, of course, expand into the other robotic categories and into automotive in the long term.\u201d\n\nThe name Sonair is a play on the 3D capabilities of water-traveling sonar, but applied to sensors that read signals in the air \u2014 effectively what the startup has produced.\n\nSandven is an engineer and entrepreneur whose previous startup, GasSecure, built gas sensors based on MEMS technology \u2014 microelectromechanical systems combining mechanical and electronic components to create miniature devices with moving parts. (The petrochemical industry is a major part of Norway\u2019s national economy.)\n\nAfter GasSecure was acquired by a German industrial safety specialist, Sandven started thinking about other uses of MEMS technology, and looked into research from SINTEF, a group that works with Norway\u2019s main science and technological university to commercialize research. Dozens of companies have spun out of the group\u2019s work over the years.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nSINTEF had created a new kind of MEMS-related ultrasonic sensor, he said, \u201cwhich was ready for commercialization.\u201d Sandven acquired the IP for the technology (specifically for acoustic ranging and detection), recruited the researchers who created it, and Sonair was born.\n\nAlthough lidar has been a standard part of autonomous systems development in recent years, there is still space for complementary or alternative approaches. Lidar is still considered expensive, it has issues with range, and still faces interference from light sources, certain surfaces, and materials.\n\nWhile companies like Mobileye are looking more seriously at other alternatives like radar, Sandven believes Sonair has a viable chance, since its technology will reduce the overall cost of sensor packages by between 50% and 80%.\n\n\u201cOur mission is to replace lidar,\u201d he said.\n\nThe ultrasound sensors and related software that Sonair has built to \u201cread\u201d the data from the sensors does not work in a vacuum. Like lidar, it works in concert with cameras to triangulate and provide more accurate pictures to the autonomous system in question.\n\nSonair\u2019s ultrasound tech is based on a \u201cbeamforming\u201d method, which is also what is used in radar. The company says the data it picks up is then processed and combined using AI \u2014 specifically object recognition algorithms \u2014 to create spatial information from sound waves. The hardware using the technology (in initial cases, mobile robots) gets a 180-degree field of view with a range of 5 meters and can use fewer sensors while addressing some of the shortcomings of lidar.\n\nThere are some interesting ideas still to be explored here. The company\u2019s focus right now is on new techniques to improve how well autonomous systems can understand the objects in front of them. The tech, however, is small and also has the potential to be applied in other form factors. Could it be, for example, used in handsets or wearables as a complement or replacement for pressure-based haptic feedback?\n\n\u201cWhat\u2019s being done today by other companies is [focused on] touch sensors,\u201d Sandven said. \u201cAfter you touch something, the device will measure the pressure or how hard or soft you\u2019re touching. Where we come in is the moment before you touch. So if you have a hand approaching something, you can respond already with our technology. You can move very fast towards the objects. But then you get precision distance measurements, so you can be very soft in the touch. It\u2019s not what we\u2019re doing right now, but it\u2019s something we could do.\u201d\n\nSagar Chandna from RunwayFBU projects that 2024 will see 200,000 autonomous mobile robots produced, working out to a market of $1.4 billion. That gives Sonair an immediate market opportunity as a less-expensive alternative for computer vision components.\n\n\u201cWith reduced costs in sensor technology and AI advancements in perception and decision-making, industries from manufacturing to healthcare are poised to benefit,\u201d said Skyfall partner Preben Songe-M\u00f8ller."}