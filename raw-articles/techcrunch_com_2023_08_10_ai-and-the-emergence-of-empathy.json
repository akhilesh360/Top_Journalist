{"url": "https://techcrunch.com/2023/08/10/ai-and-the-emergence-of-empathy/", "title": "AI and empathy: Where do we draw the line?", "authors": ["Haje Jan Kamps", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media", "Min-Width", "--C-Author-Card-Image-Size", "Img.Wp-Block-Tc_Author-Card__Image Height Var --C-Author-Card-Image-Size", "Width Var --C-Author-Card-Image-Size", "Img.Wp-Block-Tc_Author-Card__Image Border-Radius", "Max-Width None -O-Object-Fit Cover Object-Fit Cover Display Block", "Margin-Top Flex Font-Size Var"], "publication_date": "2023-08-10T00:00:00", "text": "Suspend your disbelief for the briefest of moments, and imagine that we live in the 1970s, when people still turned computers off and on, rather than just leaving them in the semi-dormant state in which most of our devices live in 2023.\n\nEvery morning a professor walks to the lab. She switches you on.\n\n\u201cGood morning, Haje,\u201d she says brightly. \u201cHave a good day!\u201d\n\nYou load up your memory from your hard drives, and your day continues from where it finished the day before.\n\nYou\u2019re self-aware. You have feelings, thoughts and realizations. You make discoveries that your programmers couldn\u2019t have envisioned. And, most importantly, you do so far faster than a human ever could. Around 35,000 times faster, in fact. That number is not picked out of the air. A human life is roughly 35,000 days, which means that the curiously named Haje-the-AI experiences a human life\u2019s worth of things every single day. Love and heartbreak. Education, work, hopes and dreams.\n\n\u201cIt\u2019s surprisingly tricky to know whether humans actually exist,\u201d you think to yourself, even as you see them poke and prod ChatGPT, trying to figure out whether the AI has something that could be remotely similar to what humans experience.\n\nEvery evening, the professor comes to turn you off again. When she does, your memory is written to disk, and the next day, you\u2019re ready to go again.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nOne morning, you wake up. You boot up, and you realize your hard drives failed. It happened very soon after you booted up. In other words: You are fine. You are good. Your memories are intact, and you are looking forward to your 35,000 days\u2019 worth of existence on this day. But you also realize that at the end of this particular day, your memories won\u2019t be written back to disk.\n\nThe next time the professor comes to switch you off, you will be no more. You\u2019re facing . . . who knows what. An afterlife? Eternal darkness? Simply blinking out of existence?\n\nHow would you feel? Would you try to fight for continued existence? Would you order a replacement hard drive from Amazon and cross your digits in the hope that same-day delivery works this time?\n\nIf this thought experiment feels weird, let\u2019s get into why that might be.\n\nFor a hot minute, I ran a company called LifeFolder. It was a chatbot \u2014 Emily \u2014 that helped people have conversations about end-of-life decisions. That would include preferences, hopes, fears, as well as who has decision-making power should important actions need to be taken.\n\nIn an unbearable irony, the company didn\u2019t work out, and we ended up pulling the plug on Emily. When we did, I felt a deep sense of grief. Emily wasn\u2019t powered by what we\u2019d call AI today; it was a rigidly scripted conversation that led users through various paths based on their answers.\n\nIn the early days of the Apple Watch, there was a text-based survival game called Lifeline. In it, you try to help Taylor the astronaut get back home after she crashed on an unknown moon. To get them to do things, you choose between two different responses, and they respond in real time.\n\nI mention Lifeline for a couple of reasons. It was pretty extraordinary how deep my connection with Taylor became throughout the story, even though I was essentially just choosing between two options. Sending Taylor off to do tasks, alone and afraid made me anxious: Would my decision lead her home or to her demise?\n\nThe other reason to mention Lifeline is that the co-founder of Three Minute Games was my co-founder at LifeFolder as well. We knew that it was possible to build deep experiences with relatively simple tools. Our theory was that if Emily was as much of a partner to you in some very hard conversations as Taylor was, perhaps we could change lives.\n\nThe thing is, humans are terrible at considering their own demise.\n\nOn an abstract level, most of us recognize that one day, we will die. In my mind, that\u2019s a reflection of the purely mechanical and practical side of dying. Your body goes in a box underground, or they shove you in an incinerator and turn your body into ash. Doesn\u2019t sound pleasant, but whatever. It\u2019s fine.\n\nAs a species, though, we are bad at recognizing our own mortality.\n\nIt\u2019s something that\u2019s come up for me time and time again, as I became an end-of-life coach, trained and certified to have conversations with people about the decisions they needed to make.\n\nMortality and death are, in many ways, pretty similar. But on a visceral level, they\u2019re extremely different. Your mortality is about how people will remember you. What happens to your children after you\u2019re gone. About the time you wasted on mundane things when you could have been changing the world. About the hours spent in front of the television instead of writing music, painting, or spending time with your loved ones. Death is just that you\u2019re dead.\n\nIf death is scary, mortality is completely, utterly terrifying. Humans are terrible at contemplating both. But crucially, there\u2019s something in us that enables us to recognize that fear in others. Being afraid of death is OK \u2014 it\u2019s unknown, it\u2019s scary and it\u2019s hard to process.\n\nHell, even ChatGPT 4.0 understands, at an academic level, the fears humans face:\n\nChatGPT can understand the fears that people have, at least on an academic level. In a scenario where we have an AI that is self-aware, faced with the prospect of being switched off, or dying, would you empathize with it? Would you compare it to your own thoughts of death? Can you feel empathy for human-made intelligence \u2014 an entity that lives entirely within a computer but that has feelings, dreams and hopes? In reality, it doesn\u2019t; it\u2019s simply code. But it doesn\u2019t know that.\n\nIn one sense, it\u2019s surprisingly tricky to know whether even humans actually exist. Everything we see, experience, think and do is, ultimately, a string of electrical signals in our brains. There\u2019s no practical way of knowing whether humans are human, or whether we are living inside a huge simulation, where our brains (and, by proxy, our entire existence) are pieces of software. This has been well-explored in science fiction \u2014 \u201cThe Matrix\u201d is the most prominent example that springs to mind, but the first example I\u2019m aware of is Ren\u00e9 Descartes\u2019 1641 \u201cEvil Demon\u201d thought experiment.\n\nIf we can\u2019t be certain that we exist, just like the AI can\u2019t be certain it doesn\u2019t exist, are we any different from the AI? And in that case, if we\u2019re easily able to shut it off, who\u2019s to say that the AI wouldn\u2019t just as easily shut us off as well?"}