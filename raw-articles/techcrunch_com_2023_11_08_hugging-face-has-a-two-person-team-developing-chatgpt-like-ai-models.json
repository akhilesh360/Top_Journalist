{"url": "https://techcrunch.com/2023/11/08/hugging-face-has-a-two-person-team-developing-chatgpt-like-ai-models/", "title": "Hugging Face has a two-person team developing ChatGPT-like AI models", "authors": ["Kyle Wiggers", "Ai Editor", "Amanda Silberling", "Rebecca Bellan", "Lorenzo Franceschi-Bicchierai", "Sean O'Kane", "Kirsten Korosec", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media", "Min-Width"], "publication_date": "2023-11-08T00:00:00", "text": "AI startup Hugging Face offers a wide range of data science hosting and development tools, including a GitHub-like portal for AI code repositories, models and datasets, as well as web dashboards to demo AI-powered applications.\n\nBut some of Hugging Face\u2019s most impressive \u2014 and capable \u2014 tools these days come from a two-person team that was formed just in January.\n\nH4, as it\u2019s called \u2014 \u201cH4\u201d being short for \u201chelpful, honest, harmless and huggy\u201d \u2014 aims to develop tools and \u201crecipes\u201d to enable the AI community to build AI-powered chatbots along the lines of ChatGPT. ChatGPT\u2019s release was the catalyst for H4\u2019s formation, in fact, according to Lewis Tunstall, a machine learning engineer at Hugging Face and one of H4\u2019s two members.\n\n\u201cWhen ChatGPT was released by OpenAI in late 2022, we started brainstorming on what it might take to replicate its capabilities with open source libraries and models,\u201d Tunstall told TechCrunch in an email interview. \u201cH4\u2019s primary research focus is around alignment, which broadly involves teaching LLMs how to behave according to feedback from humans (or even other AIs).\u201d\n\nH4 is behind a growing number of open source large language models, including Zephyr-7B-\u03b1, a fine-tuned, chat-centric version of the eponymous Mistral 7B model recently released by French AI startup Mistral. H4 also forked Falcon-40B, a model from the Technology Innovation Institute in Abu Dhabi \u2014 modifying the model to respond more helpfully to requests in natural language.\n\nTo train its models, H4 \u2014 like other research teams at Hugging Face \u2014 relies on a dedicated cluster of more than 1,000 Nvidia A100 GPUs. Tunstall and his other H4 co-worker, Ed Beeching, are based remotely in Europe, but receive support from several internal Hugging Face teams, among them the model testing and evaluation team.\n\n\u201cThe small size of H4 is a deliberate choice, as it allows us to be more nimble and adapt to an ever-changing research landscape,\u201d Beeching told TechCrunch via email. \u201cWe also have several external collaborations with groups such as LMSYS and LlamaIndex, who we collaborate with on joint releases.\u201d\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nLately, H4 has been investigating different alignment techniques and building tools to test how well techniques proposed by the community and industry really work. The team this month released a handbook containing all the source code and datasets they used to build Zephyr, and H4 plans to update the handbook with code from its future AI models as they\u2019re released.\n\nI asked whether H4 had any pressure from Hugging Face higher-ups to commercialize their work. The company, after all, has raised hundreds of millions of dollars from a pedigreed cohort of investors that includes Salesforce, IBM, AMD, Google, Amazon Intel and Nvidia. Hugging Face\u2019s last funding round valued it at $4.5 billion \u2014 reportedly more than 100 times the company\u2019s annualized revenue.\n\nTunstall said that H4 doesn\u2019t directly monetize its tools. But he acknowledged that the tools do feed into Hugging Face\u2019s Expert Acceleration Program, Hugging Face\u2019s enterprise-focused offering that provides guidance from Hugging Face teams to build custom AI solutions.\n\nAsked if he sees H4 in competition with other open source AI initiatives, like EleutherAI and LAION, Beeching said that it isn\u2019t H4\u2019s objective. Rather, he said, the intention is to \u201cempower\u201d the open AI community by releasing the training code and datasets associated with H4\u2019s chat models.\n\n\u201cOur work would not be possible without the many contributions from the community,\u201d Beeching said."}