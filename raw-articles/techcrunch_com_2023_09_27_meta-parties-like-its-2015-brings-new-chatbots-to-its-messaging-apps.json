{"url": "https://techcrunch.com/2023/09/27/meta-parties-like-its-2015-brings-new-chatbots-to-its-messaging-apps/", "title": "Meta parties like it\u2019s 2015, brings new chatbots to its messaging apps", "authors": ["Kyle Wiggers", "Ai Editor", "Zack Whittaker", "Rebecca Bellan", "Amanda Silberling", "Tim De Chant", "Connie Loizos", "Maxwell Zeff", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media"], "publication_date": "2023-09-27T00:00:00", "text": "Meta, angling for a seat at the AI chatbot table, is launching a host of new AI-powered bots across its messaging apps, including WhatsApp, Messenger and Instagram. They\u2019re available for select users in beta in the U.S. as of today.\n\nOne is an AI assistant called Meta AI, which, judging by The Verge\u2019s hands-on piece, is exceptionally similar to chatbots like OpenAI\u2019s ChatGPT and Anthropic\u2019s Claude 2. Meta AI \u2014 which will soon come to Meta\u2019s newly announced Quest 3 VR headset, Meta CEO Mark Zuckerberg said onstage at Meta\u2019s Connect conference today \u2014 can help plan a trip with friends in a group chat, answer general-knowledge questions and search the internet across Microsoft\u2019s Bing to provide real-time web results.\n\nThis reporter couldn\u2019t help but be reminded of M, Facebook\u2019s ill-fated virtual assistant that could perform tasks like making plans, automating payments and placing a phone call on a user\u2019s behalf. M was only ever available to about 2,000 people living in California and suffered from development neglect.\n\nBut Meta AI, powered by a \u201ccustom-made\u201d large language model, is set to get a much broader release. And unlike M, which relied in part on a team of humans to fulfill requests, Meta AI is entirely automated, with a model that can refer back to previous conversations and that\u2019s been tuned to give \u201cvery concise\u201d answers. Perhaps that\u2019ll make a difference.\n\nMeta AI can be invoked in any chat, Meta says. And like ChatGPT, it can generate watermarked images leveraging a text-to-image model called Emu, developed by Meta\u2019s AI research division.\n\nBeyond Meta AI, Meta today introduced a range of \u201cAI characters\u201d \u2014 basically chatbots tuned to channel certain personalities and mimic celebrities, including Kendall Jenner, Dwyane Wade, MrBeast, Paris Hilton, Charli D\u2019Amelio and Snoop Dogg (additional bots, including for Bear Grylls, Chloe Kim and Josh Richards, are on the way). Like Meta AI, the chatbots \u2014 which have profile images, either illustrated or real life \u2014 live in Meta\u2019s messaging apps. And as you chat with them, the avatars subtly animate based on the conversation.\n\nThis all sounds . . . interesting in theory. But very recent history has shown that even the best AI chatbots can go off the rails, making things up and generally missing key points in conversations.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nMeta says that it spent 6,000 hours finding problematic use cases and recruiting employees to interact with the models internally before releasing them. And it claims that it\u2019s developed new tech to catch and take action on content that violates its policies; prevented chatbots other than Meta AI from searching the web; and made its new chatbot features available to researchers through its bug bounty program.\n\nWe\u2019ll have to see how well they hold up to real-world testing, though."}