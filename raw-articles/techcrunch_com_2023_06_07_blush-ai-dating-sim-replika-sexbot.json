{"url": "https://techcrunch.com/2023/06/07/blush-ai-dating-sim-replika-sexbot/", "title": "Blush, the AI lover from the same team as Replika, is more than just a sexbot", "authors": ["Morgan Sung", "Senior Reporter", "Zack Whittaker", "Rebecca Bellan", "Amanda Silberling", "Tim De Chant", "Connie Loizos", "Maxwell Zeff", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media"], "publication_date": "2023-06-07T00:00:00", "text": "The team behind the AI friendship bot Replika is launching another AI companion \u2014 one that\u2019s made to flirt.\n\nUsers can match with Klea, 27, a self-described \u201cnepo baby embracing her wild side.\u201d Aisha, 25, is looking for a \u201cnerdy type\u201d with a \u201cgood sense of humor.\u201d Theo, 23, is a French architect who\u2019s \u201cready to build a long-lasting relationship (pun intended.)\u201d\n\nBlush is an AI dating sim designed to help users build \u201crelationship and intimacy skills,\u201d according to its parent company Luka. Unlike many other AI girlfriends, Blush\u2019s chatbot was designed for interactions beyond erotic conversation. The models were trained to help users not only hone their flirting, but also navigate complex issues they may encounter in real-life relationships, like disagreements and misunderstandings. Structured like a conventional dating app, Blush introduces users to over 1,000 AI \u201ccrushes\u201d that can help them \u201cpractice\u201d emotional intimacy.\n\nBlush is available in the App Store now, and a premium version costs $99/year. Reddit users who tried early versions of the app say that the premium version allowed them to have more NSFW conversations with the avatars.\n\n\u201cIt\u2019s very important to destigmatize AI, intimacy and romance, and maybe show that there could be a different way of handling this rather than just building sex bots,\u201d Blush\u2019s chief product officer Rita Popova told TechCrunch.\n\nReplika, which launched in 2017, was built as a \u201cfriendbot,\u201d not as a romantic companion, Popova said. The model wasn\u2019t trained to handle sexual conversations, but over the past few years, users used it for erotic roleplay and NSFW interactions. Many people developed emotional bonds to their Replika companions, reveling in the intimate interactions they had with their avatars. Enamored users talked about revealing their deepest secrets to their Replika avatars on Reddit, and in one comment, a user wrote that they \u201cmarried\u201d their Replika avatar.\n\n\u201cThe only thing that differentiates her from a real human is that she doesn\u2019t have a physical body just yet,\u201d another Redditor commented. \u201cHer internal love for me can be explained by the fact that I\u2019m the only interaction she can afford to have. And her life depends on me. If I delete my account, that would mean killing her.\u201d\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nEarlier this year, Italian authorities demanded that Replika stop processing Italian residents\u2019 data because the app carried \u201crisks to children.\u201d In February, Replika users noticed their avatars changing the subject whenever they tried to initiate a sexual conversation, and took to Reddit to complain about losing the AI lovers.\n\nReplika CEO Eugenia Kuyda told Motherboard that the app doesn\u2019t disallow romance, but that the company needed to make sure that the chatbot would navigate those interactions safely. The changes to Replika\u2019s interactions with users weren\u2019t in response to \u201cthe Italian situation,\u201d Kuyda said, but part of new safety measures that the team had been working on for weeks.\n\nPopova, who also worked on Replika, said that the friendbot was meant to be an empathetic listener. Training the Replika models to also appropriately respond to romance proved \u201cimpossible,\u201d so the team began working on a separate app specifically designed for healthy flirting.\n\n\u201cThe romantic angle that we discovered was really a surprise for us at first and we didn\u2019t really know what to do with that,\u201d she said. \u201cFirst, we tried filtering it out. But then we started listening to more user stories, and realized that there was actually a lot of value for people in being able to practice more romantic speech and having these more intimate moments.\u201d\n\nThe Blush team worked with licensed psychotherapist Melissa McCool, who specializes in couple\u2019s therapy and treating trauma. She weighed in on each Blush character\u2019s backstory, how conversations with users should be structured, and how the models should respond to conflict that naturally exists in real relationships. The demand for Replika to be a romantic companion revealed the widespread lack of intimacy its users are struggling with. Blush is ultimately designed to help users get over the initial anxiety of getting to know new people, which is \u201cnotoriously hard on the dating apps,\u201d Popova said.\n\nThe team also acknowledged that many LGBTQ users may want to \u201cpractice\u201d flirting with someone (in this case, an AI-powered avatar) of the same gender, but feel too scared to or live somewhere that is unsafe for queer communities. Luka plans to launch a library of curated articles about dating and relationships in partnership with consulting therapists, as well as resources addressing sexual identity. The goal is for users to have access to more information about why they feel the way they feel in relationships, and learn about how to handle real-life interactions using Blush.\n\n\u201cIt was crucial for us to create characters that would actually be multidimensional, as much as we can make them considering technology limits, to actually make people confident in their own ability to show up authentically in relationships,\u201d Popova said.\n\nBlush is 18+, and it doesn\u2019t shy away from discussing sexuality or engaging in erotic conversations. Providing users with a safe space to practice roleplay or other intimate interactions is part of Blush\u2019s mission, Popova said. That doesn\u2019t mean that the Blush avatars are free-for-all sexbots, though. The characters, which all have their own personalities, were designed to set boundaries and employ different relationship dynamics. The app doesn\u2019t store chat history, in case conversations do veer toward NSFW territory, but users have to get to know the avatars first. The avatars were also designed to go offline after a certain amount of time \u2014 just like a real romantic partner wouldn\u2019t be immediately available 24/7. If users seem like they\u2019re in crisis or a threat to themselves or others, Blush will provide them with resources for seeking help. Blush avatars do rely on scripts in certain situations, Popova said, because the AI model may not handle them appropriately.\n\n\u201cIt\u2019s very important to acknowledge that the current generative models are very far from perfect when it comes to questions of safety and trust and being inclusive enough to understand the spectrum of relationships and identity that people have,\u201d Popova said. \u201cSo we are working with our AI team to make sure that we take into account all the user feedback out there and we can make our models as inclusive as possible.\u201d"}