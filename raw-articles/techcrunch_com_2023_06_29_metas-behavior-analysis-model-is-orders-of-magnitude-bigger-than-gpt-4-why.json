{"url": "https://techcrunch.com/2023/06/29/metas-behavior-analysis-model-is-orders-of-magnitude-bigger-than-gpt-4-why/", "title": "Meta expects recommendation models \u2018orders of magnitude\u2019 bigger than GPT-4. Why?", "authors": ["Devin Coldewey", "Writer", "Kyle Wiggers", "Amanda Silberling", "Rebecca Bellan", "Lorenzo Franceschi-Bicchierai", "Sean O'Kane", "Kirsten Korosec", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media"], "publication_date": "2023-06-29T00:00:00", "text": "Meta made a remarkable claim in an announcement published today intended to give more clarity on its content recommendation algorithms. It\u2019s preparing for behavior analysis systems \u201corders of magnitude\u201d bigger than the biggest large language models out there, including ChatGPT and GPT-4. Is that really necessary?\n\nEvery once in a while Meta decides to freshen its commitment to transparency by explaining how a few of its algorithms work. Sometimes this is revealing or informative, and sometimes it only leads to more questions. This occasion is a little of both.\n\nIn addition to the \u201csystem cards\u201d explaining how AI is used in a given context or app, the social and advertising network posted an overview of the AI models it uses. For instance, it may be worthwhile to know whether a video represents roller hockey or roller derby, even though there\u2019s some visual overlap, so it can be recommended properly.\n\nIndeed Meta has been among the more prolific research organizations in the field of multimodal AI, which combines data from multiple modalities (visual and auditory, for instance) to better understand a piece of content.\n\nFew of these models are released publicly, though we frequently hear about how they are used internally to improve things like \u201crelevance,\u201d which is a euphemism for targeting. (They do allow some researchers access to them.)\n\nThen comes this interesting little tidbit as it is describing how it is building out its computation resources:\n\nIn order to deeply understand and model people\u2019s preferences, our recommendation models can have tens of trillions of parameters \u2014 orders of magnitude larger than even the biggest language models used today.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nI pressed Meta to get a little more specific about these theoretical tens-of-trillions models, and that\u2019s just what they are: theoretical. In a clarifying statement, the company said, \u201cWe believe our recommendation models have the potential to reach tens of trillions of parameters.\u201d This phrasing is a bit like saying your burgers \u201ccan\u201d have 16-ounce patties but then admitting they\u2019re still at the quarter-pounder stage. Nevertheless the company clearly states that it aims to \u201censure that these very large models can be trained and deployed efficiently at scale.\u201d\n\nWould a company build costly infrastructure for software it doesn\u2019t intend to create \u2014 or use? It seems unlikely, but Meta declined to confirm (though nor did they deny) that they are actively pursuing models of this size. The implications are clear, so while we can\u2019t treat this tens-of-trillions scale model as extant, we can treat it as genuinely aspirational and likely in the works.\n\n\u201cUnderstand and model people\u2019s preferences,\u201d by the way, must be understood to mean behavior analysis of users. Your actual preferences could probably be represented by a plaintext list a hundred words long. It can be hard to understand, at a fundamental level, why you would need a model this large and complex to handle recommendations even for a couple billion users.\n\nThe truth is the problem space is indeed huge: There are billions and billions of pieces of content all with attendant metadata, and no doubt all kinds of complex vectors showing that people who follow Patagonia also tend to donate to the World Wildlife Federation, buy increasingly expensive bird feeders and so on. So maybe it isn\u2019t so surprising that a model trained on all this data would be quite large. But \u201corders of magnitude larger\u201d than even the biggest out there, something trained on practically every written work accessible?\n\nThere isn\u2019t a reliable parameter count on GPT-4, and leaders in the AI world have also found that it\u2019s a reductive measure of performance, but ChatGPT is at around 175 billion and GPT-4 is believed to be higher than that but lower than the wild 100 trillion claims. Even if Meta is exaggerating a bit, this is still scary big.\n\nThink of it: An AI model as large or larger than any yet created\u2026 what goes in one end is every single action you take on Meta\u2019s platforms, what comes out the other is a prediction of what you will do or like next. Kind of creepy, isn\u2019t it?\n\nOf course they\u2019re not the only ones doing this. TikTok led the charge in algorithmic tracking and recommendation, and has built its social media empire on its addictive feed of \u201crelevant\u201d content meant to keep you scrolling until your eyes hurt. Its competitors are openly envious.\n\nMeta is clearly aiming to blind advertisers with science, both with the stated ambition to create the biggest model on the block, and with passages like the following:\n\nThese systems understand people\u2019s behavior preferences utilizing very large-scale attention models, graph neural networks, few-shot learning, and other techniques. Recent key innovations include a novel hierarchical deep neural retrieval architecture, which allowed us to significantly outperform various state-of-the-art baselines without regressing inference latency; and a new ensemble architecture that leverages heterogeneous interaction modules to better model factors relevant to people\u2019s interests.\n\nThe above paragraph isn\u2019t meant to impress researchers (they know all this stuff) or users (they don\u2019t understand or care). But put yourself in the shoes of an advertiser who is beginning to question whether their money is well spent on Instagram ads instead of other options. This technical palaver is meant to dazzle them, to convince them that not only is Meta a leader in AI research, but that AI genuinely excels at \u201cunderstanding\u201d people\u2019s interests and preferences.\n\nIn case you doubt it: \u201cmore than 20 percent of content in a person\u2019s Facebook and Instagram feeds is now recommended by AI from people, groups, or accounts they don\u2019t follow.\u201d Just what we asked for! So that\u2019s that. AI is working great.\n\nBut all this is also a reminder of the hidden apparatus at the heart of Meta, Google and other companies whose primary motivating principle is to sell ads with increasingly granular and precise targeting. The value and legitimacy of that targeting must be reiterated constantly even as users revolt and advertising multiplies and insinuates rather than improves.\n\nNever once has Meta done something sensible like present me with a list of 10 brands or hobbies and ask which of them I like. They\u2019d rather watch over my shoulder as I skim the web looking for a new raincoat and act like it\u2019s a feat of advanced artificial intelligence when they serve me raincoat ads the next day. It\u2019s not entirely clear the latter approach is superior to the former, or if so, how superior? The entire web has been built up around a collective belief in precision ad targeting and now the latest technology is being deployed to prop it up for a new, more skeptical wave of marketing spend.\n\nOf course you need a model with ten trillion parameters to tell you what people like. How else could you justify the billion dollars you spent training it!"}