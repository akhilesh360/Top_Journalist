{"url": "https://techcrunch.com/2022/08/25/googles-new-app-lets-you-experimental-ai-systems-like-lamda/", "title": "Google's new app lets you test experimental AI systems", "authors": ["Kyle Wiggers", "Ai Editor", "Zack Whittaker", "Rebecca Bellan", "Amanda Silberling", "Tim De Chant", "Connie Loizos", "Maxwell Zeff", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media"], "publication_date": "2022-08-25T00:00:00", "text": "Google today launched AI Test Kitchen, an Android app that allows users to try out experimental AI-powered systems from the company\u2019s labs before they make their way into production. Beginning today, folks interested can complete a sign-up form as AI Test Kitchen begins to roll out gradually to small groups in the U.S.\n\nAs announced at Google\u2019s I/O developer conference earlier this year, AI Test Kitchen will serve rotating demos centered around novel, cutting-edge AI technologies \u2014 all from within Google. The company stresses that they aren\u2019t finished products, but instead are intended to give a taste of the tech giant\u2019s innovations while offering Google an opportunity to study how they\u2019re used.\n\nThe first set of demos in AI Test Kitchen explore the capabilities of the latest version of LaMDA (Language Model for Dialogue Applications), Google\u2019s language model that queries the web to respond to questions in a human-like way. For example, you can name a place and have LaMDA offer paths to explore, or share a goal to get LaMDA to break it down into a list of subtasks.\n\nGoogle says it\u2019s added \u201cmultiple layers\u201d of protection to AI Test Kitchen in an effort to minimize the risks around systems like LaMDA, like biases and toxic outputs. As illustrated most recently by Meta\u2019s BlenderBot 3.0, even the most sophisticated chatbots today can quickly go off the rails, delving into conspiracy theories and offensive content when prompted with certain text.\n\nSystems within AI Test Kitchen will attempt to automatically detect and filter out objectionable words or phrases that might be sexually explicit, hateful or offensive, violent or illegal, or divulge personal information, Google says. But the company warns offensive text might still occasionally make it through.\n\n\u201cAs AI technologies continue to advance, they have the potential to unlock new experiences that support more natural human-computer interactions,\u201d Google product manager Tris Warkentin and director of product management Josh Woodward wrote in a blog post. \u201cWe\u2019re at a point where external feedback is the next, most helpful step to improve LaMDA. When you rate each LaMDA reply as nice, offensive, off topic or untrue, we\u2019ll use this data \u2014 which is not linked to your Google account \u2014 to improve and develop our future products.\u201d\n\nAI Test Kitchen is part of a broader, recent trend among tech giants to pilot AI technologies before they\u2019re released into the wild. No doubt informed by snafus like Microsoft\u2019s toxicity-spewing Tay chatbot, Google, Meta, OpenAI and others have increasingly opted to test AI systems among small groups to ensure they\u2019re behaving as intended \u2014 and to fine-tune their behavior where necessary.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nFor example, OpenAI several years ago released its language-generating system, GPT-3, in a closed beta before making it broadly available. GitHub initially limited access to Copilot, the code-generating system it developed in partnership with OpenAI, to select developers before launching it in generale availability.\n\nThe approach wasn\u2019t necessarily born out of the goodness of anyone\u2019s heart \u2014 by now, top tech players are well aware of the bad press that AI gone wrong can attract. By exposing new AI systems to external groups and attaching broad disclaimers, the strategy appears to be advertising the systems\u2019 capabilities while at the same time mitigating the more problematic components. Whether this is enough to ward off controversy remains to be seen \u2014 even prior to the launch of AI Test Kitchen, LaMDA made headlines for all the wrong reasons \u2014 but an influential slice of Silicon Valley seems to have confidence that it will."}