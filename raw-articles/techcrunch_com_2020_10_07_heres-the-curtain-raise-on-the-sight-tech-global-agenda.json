{"url": "https://techcrunch.com/2020/10/07/heres-the-curtain-raise-on-the-sight-tech-global-agenda/", "title": "Here\u2019s the curtain raise on the Sight Tech Global agenda", "authors": ["Ned Desmond", "Zack Whittaker", "Rebecca Bellan", "Amanda Silberling", "Tim De Chant", "Connie Loizos", "Maxwell Zeff", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media", "Min-Width"], "publication_date": "2020-10-07T00:00:00", "text": "The goal of Sight Tech Global, a virtual, global event on December 2-3, 2020, is to gather the world\u2019s top experts who are applying advanced technologies, notably AI, to the future of accessibility and assistive tech for people who are blind or visually impaired.\n\nToday we\u2019re excited to roll out most of the agenda. There are another half-dozen sessions and breakouts still to come, notably sessions on AI bias and civil rights. What we\u2019ve discovered over the many weeks of research and conversation is a consistent, strong interest on the part of researchers, technologists and product and design thinkers to convene and talk over the future \u2014 its promises, challenges and even threats.\n\nWe\u2019re delighted to have top-level talent from virtually every leading technology company, many research universities and some startups ready for fireside chats and small panel discussions with expert moderators. Some sessions will take questions from our audience as well.\n\nWhen the event dates are closer, we will add dates and times to each of these sessions as well as announce additional speakers. Register today to get a free pass and please browse the first edition of the Sight Tech Global agenda below.\n\nSeeing AI: Where does Microsoft\u2019s blockbuster app go from here?\n\nWith ever more powerful computer and data resources available in the cloud, Microsoft\u2019s Seeing AI mobile app is destined to become a steadily better ally for anyone with vision challenges. Co-founder Saqib Shaikh leads the engineering team that\u2019s charting the app\u2019s cloud-enabled future.\n\nSaqib Shaikh, co-founder of Seeing AI, Microsoft\n\nModerator: Devin Coldewey, TechCrunch\n\nThe future according to OrCam\n\nAs AI-based computer vision, voice recognition and natural language processing race ahead, the engineering challenge is to design devices that can perceive the physical world and communicate that information in a timely manner. Amnon Shashua\u2019s OrCam MyEye is the most sophisticated effort yet to merge those technologies in a seamless experience on a dedicated device.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nAmnon Shashua, co-founder of OrCam and Mobileye\n\nModerator: Matthew Panzarino, TechCrunch\n\nAccessibility from the wheels up: The Waymo fully autonomous taxi\n\nIf people who are blind or visually impaired find Uber and Lyft liberating, imagine how they will feel summoning a self-driving ride from an app on their mobile phones. But wait, how exactly will they locate the cars and what happens when they climb in? Presenter Clem Wright is responsible for the self-driving taxi\u2019s accessibility, and he will be joined by leadership from two organizations closely involved in that effort: The Lighthouse for the Blind SF and the Foundation for Blind Children.\n\nClem Wright, Accessibility product manager, Waymo\n\nMarc Ashton, CEO, Foundation for Blind Children\n\nBryan Bashin, CEO, Lighthouse for the Blind\n\nModerator: Kirsten Korosec, TechCrunch\n\nOur AI future is already here\n\nWhether it\u2019s Alexa, Tesla or Facebook, AI is already deeply embedded in our daily lives. Few understand that better than Dr. Kai-Fu Lee, a scientist who developed the first speaker-independent, continuous speech recognition system as a Ph.D. student at Carnegie Mellon, led Google in China and held senior roles at Microsoft and Apple. Today, Dr. Lee runs Sinovation Ventures, a $2 billion fund based in China, is president of the Sinovation\u2019s Artificial Intelligence Institute and has 50 million followers on social media.\n\nDr. Kai-Fu Lee, chairman and CEO, Sinovation Ventures\n\nModerator: Ned Desmond, Sight Tech Global\n\nThe future of AT devices and the companies that make them\n\nDedicated devices versus accessible platforms? Victor Reader Stream versus iPhones and Alexa? How will AT companies take advantage of a world with cloud data and edge computational power, AI algorithms and more demanding customers than ever? Humanware, eSight and APH are already looking far into that future.\n\nGilles Pepin, CEO, Humanware\n\nGreg Stilson, head of Global Innovation, APH\n\nCharles Lim, CTO, eSight\n\nModerator: Betsy Beaumon, CEO, Benetech\n\nIf the Jetsons had screen readers, would they be using keyboard commands?\n\nThe screen reader is arguably the most consequential digital technology ever for people who are blind or visually impaired. At the same time, screen readers depend on a dizzying array of keyboard commands, and \u2014 when it comes to reading websites in a browser \u2014 they struggle with the ugly reality of poor website accessibility. New technologies may lead the way to better outcomes.\n\nGlen Gordon, Software fellow, Vispero; architect, JAWS\n\nJames Teh, Accessibility engineer, Mozilla; co-founder, NVDA\n\nL\u00e9onie Watson, director, TetraLogical\n\nModerator: Matt King, Accessibility technical program manager, Facebook\n\nAlexa, what is your future?\n\nWhen Alexa launched six years ago, no one imagined that the voice assistant would reach into millions of daily lives and become a huge convenience for people who are blind or visually impaired. This fall, Alexa introduced personalization and conversational capabilities that are a step-change toward more human-like home companionship. Amazon\u2019s Josh Miele and Anne Toth will discuss the impact on accessibility as Alexa becomes more capable.\n\nAnne Toth, director, Alexa Trust at Amazon\n\nJosh Miele, principal accessibility researcher, Lab126 at Amazon\n\nModerator: Devin Coldewey, TechCrunch\n\nAugmented reality and perception: What\u2019s the best way to get the message across?\n\nIt\u2019s one thing for an AI-based system to \u201cknow\u201d when it\u2019s time to turn left, who came through the door or how far away the couch is: It\u2019s quite another to convey that information in a timely fashion with minimal distraction. Researchers are making use of haptics, visual augmented reality (AR), sound and language to figure out the right solutions.\n\nAmos Miller, Product strategist, Microsoft AI and Research\n\nAshley Tuan, VP Medical Devices, Mojo Vision\n\nSile O\u2019Modhrain, associate professor, Performing Arts Technology, University of Michigan\n\nModerator: Nick Giudice, professor of Spatial Informatics, University of Maine\n\nWayfinding: Finding the mark\n\nMap apps on mobile phones are miraculous tools accessible via voice output, but mainstream apps don\u2019t announce the detailed location information (which people who are blind or visually impaired really want), especially inside buildings and in public transportation settings. Efforts in the U.S. and U.K. are improving accessible navigation.\n\nTim Murdoch, founder and CEO, Waymap\n\nNick Giudice, professor of Spatial Informatics, University of Maine\n\nModerator: Mike May, chief evangelist, GoodMaps\n\nComputer vision, AI and accessibility: What\u2019s missing from this picture?\n\nFor an AI to interpret the visual world on behalf of people who are blind or visually impaired, the AI needs to know what it\u2019s looking at, and no less important, that it\u2019s looking at the right thing. Mainstream computer vision databases don\u2019t do that well \u2014 yet.\n\nDanna Gurari, assistant professor and director of the Image and Video Computing Group, University of Texas\n\nCecily Morrison, principal researcher human experience & design, Microsoft\n\nPatrick Clary, product manager, AI and accessibility, Google\n\nModerator: Roberto Manduchi, professor CS and Engineering, UC Santa Cruz\n\nKeep an out for more sessions and breakouts later this month. In the meantime, registration is open. Get your pass today!\n\nSight Tech Global is eager to hear from potential sponsors. We\u2019re grateful to current sponsors Amazon, Ford, Google, Microsoft, Mojo Vision, Waymo, Wells Fargo and Humanware. All sponsorship revenues go to the nonprofit Vista Center for the Blind and Visually Impaired, which has been serving the Silicon Valley area for 75 years.\n\nSpecial thanks to the Sight Tech Global advisors \u2014 Tech Matters\u2019 Jim Fruchterman, UC Santa Cruz\u2019s Roberto Manduchi, Verizon Media\u2019s Larry Goldberg, Facebook\u2019s Matt King and Be My Eyes\u2019 Will Butler \u2014 who are playing an invaluable role on this project."}