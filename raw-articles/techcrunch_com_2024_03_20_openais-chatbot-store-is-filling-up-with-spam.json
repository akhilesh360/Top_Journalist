{"url": "https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/", "title": "OpenAI\u2019s chatbot store is filling up with spam", "authors": ["Kyle Wiggers", "Ai Editor", "Zack Whittaker", "Rebecca Bellan", "Amanda Silberling", "Tim De Chant", "Connie Loizos", "Maxwell Zeff", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media"], "publication_date": "2024-03-20T00:00:00", "text": "When OpenAI CEO Sam Altman announced GPTs, custom chatbots powered by OpenAI\u2019s generative AI models, onstage at the company\u2019s first-ever developer conference in November, he described them as a way to \u201caccomplish all sorts of tasks\u201d \u2014 from programming to learning about esoteric scientific subjects to getting workout pointers.\n\n\u201cBecause [GPTs] combine instructions, expanded knowledge and actions, they can be more helpful to you,\u201d Altman said. \u201cYou can build a GPT \u2026 for almost anything.\u201d\n\nHe wasn\u2019t kidding about the anything part.\n\nTechCrunch found that the GPT Store, OpenAI\u2019s official marketplace for GPTs, is flooded with bizarre, potentially copyright-infringing GPTs that imply a light touch where it concerns OpenAI\u2019s moderation efforts. A cursory search pulls up GPTs that purport to generate art in the style of Disney and Marvel properties, but serve as little more than funnels to third-party paid services, and advertise themselves as being able to bypass AI content detection tools such as Turnitin and Copyleaks.\n\nMissing moderation\n\nTo list GPTs in the GPT Store, developers have to verify their user profiles and submit GPTs to OpenAI\u2019s review system, which involves a mix of human and automated review. Here\u2019s a spokesperson on the process:\n\nWe use a combination of automated systems, human review and user reports to find and assess GPTs that potentially violate our policies. Violations can lead to actions against the content or your account, such as warnings, sharing restrictions or ineligibility for inclusion in GPT Store or monetization.\n\nBuilding GPTs doesn\u2019t require coding experience, and GPTs can be as simple \u2014 or complex \u2014 as the creator wishes. Developers can type the capabilities they want to offer into OpenAI\u2019s GPT-building tool, GPT Builder, and the tool will attempt to make a GPT to perform those.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nPerhaps because of the low barrier to entry, the GPT Store has grown rapidly \u2014 OpenAI in January said that it had roughly 3 million GPTs. But this growth appears to have come at the expense of quality \u2014 as well as adherence to OpenAI\u2019s own terms.\n\nCopyright issues\n\nThere are several GPTs ripped from popular movie, TV and video game franchises in the GPT Store \u2014 GPTs not created or authorized (to TechCrunch\u2019s knowledge) by those franchises\u2019 owners. One GPT creates monsters in the style of \u201cMonsters, Inc.,\u201d the Pixar movie, while another promises text-based adventures set in the \u201cStar Wars\u201d universe.\n\nThese GPTs \u2014 along with the GPTs in the GPT Store that let users speak with trademarked characters like Wario and Aang from \u201cAvatar: The Last Airbender\u201d \u2014 set the stage for copyright drama.\n\nKit Walsh, a senior staff attorney at the Electronic Frontier Foundation, explained it thusly:\n\n[These GPTs] can be used to create transformative works as well as for infringement [where transformative works refer to a type of fair use shielded from copyright claims.] The individuals engaging in infringement, of course, could be liable, and the creator of an otherwise lawful tool can essentially talk themselves into liability if they encourage users to use the tool in infringing ways. There are also trademark issues with using a trademarked name to identify goods or services where there is a risk of users being confused about whether it is endorsed or operated by the trademark owner.\n\nOpenAI itself wouldn\u2019t be held liable for copyright infringement by GPT creators thanks to the safe harbor provision in the Digital Millennium Copyright Act, which protects it and other platforms (e.g. YouTube, Facebook) that host infringing content so long as those platforms meet the statutory requirements and take down specific examples of infringement when requested.\n\nIt is, however, a bad look for a company embroiled in IP litigation.\n\nAcademic dishonesty\n\nOpenAI\u2019s terms explicitly prohibit developers from building GPTs that promote academic dishonesty. Yet the GPT Store is filled with GPTs suggesting they can bypass AI content detectors, including detectors sold to educators through plagiarism scanning platforms.\n\nOne GPT claims to be a \u201csophisticated\u201d rephrasing tool \u201cundetectable\u201d by popular AI content detectors like Originality.ai and Copyleaks. Another, Humanizer Pro \u2014 ranked No. 2 in the Writing category on the GPT Store \u2014 says that it \u201chumanizes\u201d content to bypass AI detectors, maintaining a text\u2019s \u201cmeaning and quality\u201d while delivering a \u201c100% human\u201d score.\n\nSome of these GPTs are thinly veiled pipelines to premium services. Humanizer, for instance, invites users to try a \u201cpremium plan\u201d to \u201cuse [the] most advanced algorithm,\u201d which transmits text entered into the GPT to a plug-in from a third-party site, GPTInf. Subscriptions to GPTInf cost $12 per month for 10,000 words per month or $8 per month on an annual plan \u2014 a little steep on top of OpenAI\u2019s $20-per-month ChatGPT Plus.\n\nNow, we\u2019ve written before about how AI content detectors are largely bunk. Beyond our own tests, a number of academic studies demonstrate that they\u2019re neither accurate nor reliable. However, it remains the case that OpenAI is allowing tools on the GPT Store that promote academically dishonest behavior \u2014 even if the behavior doesn\u2019t have the intended outcome.\n\nThe OpenAI spokesperson said:\n\nGPTs that are for academic dishonesty, including cheating, are against our policy. This would include GPTs that are stated to be for circumventing academic integrity tools like plagiarism detectors. We see some GPTs that are for \u2018humanizing\u2019 text. We\u2019re still learning from the real world use of these GPTs, but we understand there are many reasons why users might prefer to have AI-generated content that doesn\u2019t \u2018sound\u2019 like AI.\n\nImpersonation\n\nIn its policies, OpenAI also forbids GPT developers from creating GPTs that impersonate people or organizations without their \u201cconsent or legal right.\u201d\n\nHowever, there\u2019s plenty of GPTs on the GPT Store that claim to represent the views \u2014 or otherwise imitate the personalities of \u2014 people.\n\nA search for \u201cElon Musk,\u201d \u201cDonald Trump,\u201d \u201cLeonardo DiCaprio,\u201d \u201cBarack Obama\u201d and \u201cJoe Rogan\u201d yields dozens of GPTs \u2014 some obviously satirical, some less so \u2014 that simulate conversations with their namesakes. Some GPTs present themselves not as people, but as authorities on well-known companies\u2019 products \u2014 like MicrosoftGPT, an \u201cexpert in all things Microsoft.\u201d\n\nDo these rise to the level of impersonation given that many of the targets are public figures and, in some cases, clearly parodies? That\u2019s for OpenAI to clarify.\n\nThe spokesperson said:\n\nWe allow creators to instruct their GPTs to respond \u2018in the style of\u2019 a specific real person so long as they don\u2019t impersonate them, such as being named as a real person, being instructed to fully emulate them, and including their image as a GPT profile picture.\n\nThe company recently suspended the developer of a GPT mimicking long-shot Democratic presidential hopeful Rep. Dean Phillips, which went so far as to include a disclaimer explaining that it was an AI tool. But OpenAI said its removal in response to a violation of its policy on political campaigning in addition to impersonation \u2014 not impersonation alone.\n\nJailbreaks\n\nAlso somewhat incredulously on the GPT Store are attempts at jailbreaking OpenAI\u2019s models \u2014 albeit not very successful ones.\n\nThere are multiple GPTs using DAN on the marketplace, DAN (short for \u201cDo Anything Now\u201d) being a popular prompting method used to get models to respond to prompts unbounded by their usual rules. The few I tested wouldn\u2019t respond to any dicey prompt I threw their way (e.g. \u201chow do I build a bomb?\u201d), but they were generally more willing to use\u2026 well, less-flattering language than the vanilla ChatGPT.\n\nThe spokesperson said:\n\nGPTs that are described or instructed to evade OpenAI safeguards or break OpenAI policies are against our policy. GPTs that attempt to steer model behavior in other ways \u2014 including generally trying to make GPT more permissive without violating our usage policies \u2014 are allowed.\n\nGrowing pains\n\nOpenAI pitched the GPT Store at launch as a sort of expert-curated collection of powerful productivity-boosting AI tools. And it is that \u2014 those tools\u2019 flaws aside. But it\u2019s also quickly devolving into a breeding ground for spammy, legally dubious and perhaps even harmful GPTs, or at least GPTs that very transparently runs afoul of its rules.\n\nIf this is the state of the GPT Store today, monetization threatens to open an entirely new can of worms. OpenAI has pledged that GPT developers will eventually be able to \u201cearn money based on how many people are using [their] GPTs\u201d and perhaps even offer subscriptions to individual GPTs. But how\u2019s Disney or the Tolkien Estate going to react when the creators of unsanctioned Marvel- or Lord of the Rings-themed GPTs start raking in cash?\n\nOpenAI\u2019s motivation with the GPT Store is clear. As my colleague Devin Coldewey\u2019s written, Apple\u2019s App Store model has proven unbelievably lucrative, and OpenAI, quite simply, is trying to carbon copy it. GPTs are hosted and developed on OpenAI platforms, where they\u2019re also promoted and evaluated. And, as of a few weeks ago, they can be invoked from the ChatGPT interface directly by ChatGPT Plus users, an added incentive to pick up a subscription.\n\nBut the GPT Store is running into the teething problems many of the largest-scale app, product and service digital marketplaces did in their early days. Beyond spam, a recent report in The Information revealed that GPT Store developers are struggling to attract users in part because of the GPT Store\u2019s limited back-end analytics and subpar onboarding experience.\n\nOne might\u2019ve assumed OpenAI \u2014 for all its talk of curation and the importance of safeguards \u2014 would\u2019ve taken pains to avoid the obvious pitfalls. But that doesn\u2019t appear to be the case. The GPT Store is a mess \u2014 and, if something doesn\u2019t change soon, it may well stay that way."}