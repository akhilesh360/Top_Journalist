{"url": "https://techcrunch.com/2023/11/16/blackshark-ais-orca-huntr-lets-you-build-orbital-intelligence-models-with-a-scribble/", "title": "Blackshark.ai\u2019s Orca Huntr lets you build orbital intelligence models with a scribble", "authors": ["Devin Coldewey", "Writer", "Kyle Wiggers", "Amanda Silberling", "Rebecca Bellan", "Lorenzo Franceschi-Bicchierai", "Sean O'Kane", "Kirsten Korosec", "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var", "Media"], "publication_date": "2023-11-16T00:00:00", "text": "Blackshark.ai has already made a digital twin of the Earth, and its next play further democratizes the hitherto lofty (if you will) world of geospatial intelligence. Continuing the nautical theme, its Orca Huntr tool is an AI-powered tool for finding and tracking anything from orbit \u2014 and it\u2019s so simple that a child, or even a member of Congress, could use it.\n\nThe company also announced $15 million in new funding that should help kickstart this new line of business.\n\nThe startup was born out of the gaming industry, bringing a fresh perspective to the matters of interpreting and using orbital and aerial imagery. We wrote in 2020 the detailed story of how they created the digital twin of Earth, but the short version is that they built a central system for interpreting imagery that varied widely over time and origin.\n\n\u201cFrom day one, we had to design technology flexible enough to digest all this data,\u201d CEO Michael Putz told me in an interview about the new feature and funding. And now they\u2019re working on a way for people to get more value out of this digital Earth without needing a PhD in machine learning or even a few years of coding experience.\n\nObviously no-code geospatial AI data play is something of a buzzword bingo, but once you see the product in action it\u2019s easy to see how it could make waves. The complexity of the product is hidden behind an almost ludicrously simple interface: You scribble on the part of the image you want to find more of, and the system finds more of that thing, pretty much instantly. That\u2019s\u2026 it.\n\nReally! Look:\n\nWell, there\u2019s a little more to it than that. You can also scribble in a different color in the negative space to say \u201cnot this part,\u201d and there are a few knobs to twiddle for advanced features. But the entire point of Orca Huntr was to allow anyone who can see a feature and scribble on it to, essentially, build a machine learning engine to detect every other instance of it \u2014 every instance in the imagery you upload, or on the planet if you\u2019re feeling expansive.\n\nTechcrunch event Join us at TechCrunch Sessions: AI Secure your spot for our leading AI industry event with speakers from OpenAI, Anthropic, and Cohere. For a limited time, tickets are just $292 for an entire day of expert talks, workshops, and potent networking. Exhibit at TechCrunch Sessions: AI Secure your spot at TC Sessions: AI and show 1,200+ decision-makers what you\u2019ve built \u2014 without the big spend. Available through May 9 or while tables last. Berkeley, CA | REGISTER NOW\n\nSay you wanted to identify all the buildings with solar panels on their roofs. Scribble on them. Trying to outline burned areas in wildfire zones? Scribble on them. Counting fishing boats in an area of the ocean? Scribble. And of course, want to identify locations of adversary assets? Scribble on them in a secure area.\n\nOrdinarily this type of object detection requires a bit more time, effort and expertise. The labeling process for large-scale imagery is not particularly modern or efficient, and when done at scale is often outsourced \u2014 a multibillion-dollar industry. Asking a firm to go through a hundred images and painstakingly label every river, then training a computer vision model on those and getting it all back to you, can take weeks or more, plus a fair amount of money. And if you\u2019re doing sensitive work like military intelligence, you have to do it all internally, which means having a team capable of doing so, and most don\u2019t.\n\nDuring a demo of the technology, Putz explained how their approach differs, beyond the UI, from those annotation and object recognition services offered by competitors.\n\n\u201cWe\u2019re not trying to fully automate it; we\u2019re using an intelligent human in the loop, which other solutions don\u2019t want. But the AI is never 100% accurate, so you refine it\u2026 but everyone else goes the traditional way of doing labeling,\u201d he said, which is to say sending it off to the professionals (and by extension, whoever they pass it off to). \u201cOrca makes it no code and simple, more accurate and secure \u2014 any user that can hold a mouse can detect anything.\u201d\n\nIf the jet-detection algorithm you get is only 80% accurate, you used to have to send it back to the maker with another hundred annotated images and wait for them to get back to you. With Orca Huntr, it might literally be as simple as adding one more brush stroke \u2014 the model updates in real time and you can see whether it\u2019s better. It\u2019s an evolution of the very tools they used (and declined to give details on at the time) during the creation of the Earth twin for Microsoft\u2019s flight simulator.\n\n\u201cYou actually start to learn how AI works, and what training and annotation means, and what you have to do to get good results,\u201d Putz said. \u201cIt\u2019s actually fun to train with it \u2014 it\u2019s like a challenge, to see how many brush strokes you need.\u201d\n\nIt vastly simplifies and accelerates the common task of \u201cfind all the X in this set of images,\u201d which is of equal interest to realtors and developers as it is to governments, scientists and military types. You might think that providing this capability would allow anyone to do the necessary work themselves, but Putz said there\u2019s actually been an increase in clients asking for soup-to-nuts solutions.\n\n\u201cWe tried to say we only provide this thin horizontal layer, but we found that customers always eventually want us to verticalize,\u201d he said. For example, a wind farm developer could use the tool to find areas with the right features for placing a dozen turbines. But they want more than that and may simply provide the imagery and constraints to Blackshark.ai, asking not only that the company find likely spots, but create line-of-sight visualizations and other real-world considerations.\n\n\u201cWe can put a wind park anywhere on the planet in 3D, then put it into Unreal [Engine] and show the mayor of a town how from this terrace or town square it wouldn\u2019t be visible,\u201d Putz said.\n\nIt\u2019s also governments from around the world that, despite the simplicity of the new interface, just don\u2019t have the familiarity with this type of work that\u2019s needed just yet. Investments in AI and data over the last decade have had mixed results, with many tools and platforms not panning out or proving too expensive or limiting.\n\n\u201cFor myself, a key learning was how important governments are as clients \u2014 and it\u2019s not just three-letter agencies, it\u2019s the forest and coastal agencies \u2014 I mean, they\u2019re the ones taking care of the planet,\u201d he said.\n\nIt helps that the company is the only one with access to investor Maxar\u2019s archive of satellite data, which covers numerous eras and satellite types, making it invaluable not just for training models but for augmenting and contextualizing other datasets. Putz cited the resilience of its systems and the ability to handle lots of different data types without breaking down as a core strength of the company.\n\nThat versatility may even allow it to generalize outside orbital imagery. A model for creating models, which is what Orca Huntr amounts to, might very well work for things other than pictures of the planet. It might be able to learn and report objects or features in microscopic industrial or medical imagery.\n\n\u201cI think it could work in radiology, doctors marking tumors and so on. I just reached out to a friendly investor to introduce me to OEMs to test it out there. And we got a very interesting request from a hard drive manufacturer,\u201d he noted. (When I asked about whale spotting, he said it was possible given the right imagery, and \u201cWe had a gentlemen already asking for Penguin colonies in Antarctica,\u201d which are famously visible from space.)\n\nThe new features were partly made possible by $15 million in new funding from (quoting from press release): \u201cExisting investors Point72 Ventures, M12 Microsoft\u2019s Venture Fund, and Maxar are joined by In-Q-Tel (IQT), Safran, ISAI Cap Venture, Capgemini\u2019s VC Fund managed by ISAI, Einstein Industries Ventures, Interwoven Ventures (formerly ROBO Global Ventures), OurCrowd, Gaingels and OpAmp Capital.\u201d That brings their total raised to $35 million.\n\nIt\u2019s always worth noting when a major tech company, a major space company and a major\u2026 however you might describe In-Q-Tel, are all on the same investment. Clearly there\u2019s a confluence of needs and opportunity here.\n\nYou\u2019ll be able to test the tool yourself come December 4, if you\u2019re a paying customer. The company declined to provide details on how it will be priced."}